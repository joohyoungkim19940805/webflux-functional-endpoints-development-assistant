package com.byeolnaerim.mongodb;


import java.lang.reflect.Field;
import java.lang.reflect.ParameterizedType;
import java.lang.reflect.Type;
import java.util.ArrayDeque;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.Deque;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicReference;
import java.util.function.BiConsumer;
import java.util.function.Consumer;
import java.util.function.Function;
import java.util.function.Predicate;
import java.util.function.Supplier;
import java.util.stream.Collectors;
import org.bson.Document;
import org.springframework.data.annotation.Id;
import org.springframework.data.domain.Sort;
import org.springframework.data.domain.Sort.Order;
import org.springframework.data.geo.Point;
import org.springframework.data.mapping.PersistentPropertyAccessor;
import org.springframework.data.mongodb.core.BulkOperations;
import org.springframework.data.mongodb.core.ReactiveBulkOperations;
import org.springframework.data.mongodb.core.ReactiveMongoTemplate;
import org.springframework.data.mongodb.core.aggregation.Aggregation;
import org.springframework.data.mongodb.core.aggregation.AggregationOperation;
import org.springframework.data.mongodb.core.aggregation.AggregationOptions;
import org.springframework.data.mongodb.core.aggregation.FacetOperation;
import org.springframework.data.mongodb.core.aggregation.ProjectionOperation;
import org.springframework.data.mongodb.core.mapping.MongoMappingContext;
import org.springframework.data.mongodb.core.mapping.MongoPersistentEntity;
import org.springframework.data.mongodb.core.mapping.MongoPersistentProperty;
import org.springframework.data.mongodb.core.query.BasicUpdate;
import org.springframework.data.mongodb.core.query.Criteria;
import org.springframework.data.mongodb.core.query.Query;
import org.springframework.data.mongodb.core.query.Update;
import org.springframework.data.repository.reactive.ReactiveCrudRepository;
import org.springframework.transaction.reactive.TransactionalOperator;
import com.byeolnaerim.mongodb.FieldsPair.Condition;
import com.byeolnaerim.mongodb.MongoQueryBuilder.AbstractQueryBuilder.ExecuteBuilder;
import com.byeolnaerim.mongodb.MongoQueryBuilder.AbstractQueryBuilder.LookupSpec;
import com.mongodb.ReadPreference;
import com.mongodb.bulk.BulkWriteResult;
import com.mongodb.client.result.DeleteResult;
import com.mongodb.client.result.UpdateResult;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import tools.jackson.databind.ObjectMapper;
import tools.jackson.databind.json.JsonMapper;


public class MongoQueryBuilder<K> {

    private final MongoTemplateResolver<K> resolver;
	
	private final ObjectMapper objectMapper;

	private final static ConcurrentHashMap<Class<? extends ReactiveCrudRepository<?, ?>>, Class<?>> entityClassCache = new ConcurrentHashMap<>();

	// ì§€êµ¬ ë°˜ì§€ë¦„ (meters)
	static final double EARTH_RADIUS_M = 6_378_137.0;

    public MongoQueryBuilder(MongoTemplateResolver<K> resolver) {

		this( resolver, JsonMapper.builder().build() );

	}

	public MongoQueryBuilder(
								MongoTemplateResolver<K> resolver,
								ObjectMapper objectMapper
	) {
        this.resolver = resolver;
		this.objectMapper = objectMapper;
    }
	public static <T> Flux<FieldsPair<String, Object>> extractFieldsPairs(
		T entity, String... fieldNames
	) {

		if (entity == null || fieldNames == null || fieldNames.length == 0) { return Flux.error( new IllegalArgumentException( "Entity or fieldNames must not be null or empty." ) ); }

		return Flux
			.fromArray( fieldNames )
			.flatMap( fieldName -> Mono.fromCallable( () -> {
				Field field = entity.getClass().getDeclaredField( fieldName );
				field.setAccessible( true );
				Object value = field.get( entity );
				return new FieldsPair<>( fieldName, value );

			} ) );
		// .onErrorMap( e -> new RuntimeException( "Failed to extract fields: " + e.getMessage(), e ) );

	}

	public static Flux<Criteria> createQueryReactive(
		Collection<FieldsPair<?, ?>> fieldsPairs
	) {


		if (fieldsPairs == null || fieldsPairs.isEmpty()) // { return Mono.error( new IllegalArgumentException( "FieldsPairs must not be null or empty." ) );
			// }
			return Flux.empty();
		return Flux
			.fromIterable( fieldsPairs )
			.flatMap( fieldsPair -> {
				String fieldName;

				if (fieldsPair.getFieldName() instanceof Enum<?> enumValue) {
					fieldName = enumValue.name();

				} else if (fieldsPair.getFieldName() instanceof String stringValue) {
					fieldName = stringValue;

				} else {
					fieldName = fieldsPair.getFieldName().toString();

				}

				Object fieldValue = fieldsPair.getFieldValue();
				FieldsPair.Condition queryType = fieldsPair.getQueryType();

				return Mono
					.just( Criteria.where( fieldName ) )
					.map( criteria -> switch (queryType) {
						case eq -> criteria.is( fieldValue );
						case notEq -> criteria.ne( fieldValue );
						case gt -> criteria.gt( fieldValue );
						case gte -> criteria.gte( fieldValue );
						case lt -> criteria.lt( fieldValue );
						case lte -> criteria.lte( fieldValue );
						case in -> {

							if (fieldValue instanceof Collection<?>) {
								yield criteria.in( (Collection<?>) fieldValue );

							} else {
								throw new IllegalArgumentException( "Field value must be a collection for 'in' query type." );

							}

						}
						case notIn -> {

							if (fieldValue instanceof Collection<?>) {
								yield criteria.nin( (Collection<?>) fieldValue );

							} else {
								throw new IllegalArgumentException( "Field value must be a collection for 'notIn' query type." );

							}

						}
						case like -> criteria.regex( fieldValue.toString(), "i" );
						case regex -> criteria.regex( fieldValue.toString() );
						case exists -> {

							if (fieldValue instanceof Boolean existsValue) {
								yield criteria.exists( existsValue );

							} else {
								throw new IllegalArgumentException( "Field value must be a Boolean for 'exists' query type." );

							}

						}
						case isNull -> criteria.is( null );
						case isNotNull -> criteria.ne( null );
						case between -> {

							if (fieldValue instanceof Collection<?> values && values.size() == 2) {
								Object[] rangeValues = values.toArray();
								yield criteria.gte( rangeValues[0] ).lte( rangeValues[1] );

							} else {
								throw new IllegalArgumentException( "Field value must be a collection of size 2 for 'between' query type." );

							}

						}
						case near -> {

							// ex) ì¢Œí‘œ ê¸°ì¤€ ê°€ê¹Œìš´ 5km ê²€ìƒ‰
							// FieldsPair.of("propertyDetail.location", new Double[]{127.0, 37.0, 5000.0},
							// FieldsPair.Query.near)
							if (fieldValue instanceof Double[] point && point.length >= 3) {
								var near = criteria.near( new Point( point[0], point[1] ) );

								if (point.length == 4) {
									near.maxDistance( point[2] ).minDistance( point[3] );

								} else {
									near.maxDistance( point[2] );

								}

								yield near;

							} else {
								throw new IllegalArgumentException( "Field value must be a collection of size 3 (geo x, geo y, max distance, min distance) for 'near' query type." );

							}

						}
						case elemMatch -> {

							/* í•„ë“œ ì˜ˆ: FieldsPair.of("propertyDetail", subFieldsPairs, Query.elemMatch)
							 * - ì—¬ê¸°ì„œ subFieldsPairsëŠ” Collection<FieldsPair<?,?>> í˜•íƒœë¼ê³  ê°€ì •. */
							if (fieldValue instanceof Collection<?> subPairs) {
								// subPairs ì•ˆì— FieldsPair<?,?> ë“¤ì´ ìˆë‹¤ê³  ê°€ì •
								// -> í•˜ìœ„ ì¡°ê±´ì„ Criteriaë¡œ ë§Œë“ ë‹¤ (AND ì—°ì‚°)
								List<Criteria> subCriteriaList = new ArrayList<>();

								for (Object o : subPairs) {

									if (o instanceof FieldsPair<?, ?> sp) {
										// ì—¬ê¸°ì„œ createSingleCriteria(sp)ë¥¼ ì¬ì‚¬ìš©
										Criteria sc = createSingleCriteria( sp );
										subCriteriaList.add( sc );

									}

								}

								// subCriteriaListë¥¼ í•˜ë‚˜ì˜ Criteriaë¡œ í•©ì¹œë‹¤(AND)
								// ex) new Criteria().andOperator(subCriteriaList.toArray(new Criteria[0]))
								Criteria subCombined = new Criteria().andOperator( subCriteriaList.toArray( new Criteria[0] ) );

								// ìµœì¢… elemMatch
								yield criteria.elemMatch( subCombined );

							} else {
								throw new IllegalArgumentException( "Field value must be a collection of FieldsPair<?,?> for 'elemMatch' query type." );

							}

						}
						default -> throw new IllegalArgumentException( "Unsupported query type: " + queryType );

					} );
				// .onErrorMap( e -> new RuntimeException( "Failed to create Criteria: " + e.getMessage(), e ) );

			} );

	}

	public static Criteria createSingleCriteria(
		FieldsPair<?, ?> pair
	) {

		String fieldName;

		if (pair.getFieldName() instanceof Enum<?>) {
			fieldName = ((Enum<?>) pair.getFieldName()).name();

		} else {
			fieldName = pair.getFieldName().toString();

		}

		Object fieldValue = pair.getFieldValue();
		FieldsPair.Condition queryType = pair.getQueryType();

		try {
			Criteria criteria = Criteria.where( fieldName );

			switch (queryType) {
				case eq:
					return criteria.is( fieldValue );
				case all:
					if (fieldValue instanceof Collection<?>) {
						return criteria.all( (Collection<?>) fieldValue );

					} else {
						throw new IllegalArgumentException( "Field value must be a collection for 'in' query type." );

					}
					// return criteria.all( fieldValue );
				case notEq:
					return criteria.ne( fieldValue );
				case gt:
					return criteria.gt( fieldValue );
				case gte:
					return criteria.gte( fieldValue );
				case lt:
					return criteria.lt( fieldValue );
				case lte:
					return criteria.lte( fieldValue );
				case in:
					if (fieldValue instanceof Collection<?>) {
						return criteria.in( (Collection<?>) fieldValue );

					} else {
						throw new IllegalArgumentException( "Field value must be a collection for 'in' query type." );

					}
				case notIn:
					if (fieldValue instanceof Collection<?>) {
						return criteria.nin( (Collection<?>) fieldValue );

					} else {
						throw new IllegalArgumentException( "Field value must be a collection for 'notIn' query type." );

					}
				case like:
					return criteria.regex( fieldValue.toString(), "i" );
				case regex:
					return criteria.regex( fieldValue.toString() );
				case exists:
					if (fieldValue instanceof Boolean) {
						return criteria.exists( (Boolean) fieldValue );

					} else {
						throw new IllegalArgumentException( "Field value must be a Boolean for 'exists' query type." );

					}
				case isNull:
					return criteria.is( null );
				case isNotNull:
					return criteria.ne( null );
				case between:
					if (fieldValue instanceof Collection<?> values && values.size() == 2) {
						Object[] rangeValues = values.toArray();
						return criteria.gte( rangeValues[0] ).lte( rangeValues[1] );

					} else {
						throw new IllegalArgumentException( "Field value must be a collection of size 2 for 'between' query type." );

					}
				case near:
					if (fieldValue instanceof Double[] point && point.length >= 3) {
						Point location = new Point( point[0], point[1] );
						Criteria nearCriteria = criteria.near( location );

						if (point.length == 4) {
							nearCriteria.maxDistance( point[2] ).minDistance( point[3] );

						} else {
							nearCriteria.maxDistance( point[2] );

						}

						return nearCriteria;

					} else {
						throw new IllegalArgumentException( "Field value must be a Double array with at least 3 elements for 'near' query type." );

					}
				case nearSphere:
					if (fieldValue instanceof Double[] p && p.length >= 3) {
						double lon = p[0], lat = p[1];
						double maxMeters = p[2];

						// ë¯¸í„°ë¥¼ ë¼ë””ì•ˆìœ¼ë¡œ ë³€í™˜
						double maxRadians = maxMeters / EARTH_RADIUS_M;

						Criteria c = criteria
							.nearSphere( new Point( lon, lat ) )
							.maxDistance( maxRadians );

						if (p.length == 4) {
							double minMeters = p[3];
							double minRadians = minMeters / EARTH_RADIUS_M;
							c.minDistance( minRadians );

						}

						return c;

					} else {
						throw new IllegalArgumentException( "nearSphere requires Double[]{lon,lat,maxMeters[,minMeters]}" );

					}
				case elemMatch:
					/* ì˜ˆ: FieldsPair.of("propertyDetail", List.of(
					 * FieldsPair.of("location", ???, Query.near),
					 * FieldsPair.of("province", "ê²½ê¸°ë„", Query.eq)
					 * ), Query.elemMatch) */
					if (fieldValue instanceof Collection<?> subPairs) {
						// subPairs ì•ˆì— FieldsPair<?,?> ë“¤ì´ ë“¤ì–´ìˆë‹¤ê³  ê°€ì •
						List<Criteria> subCriteriaList = new ArrayList<>();

						for (Object o : subPairs) {

							if (o instanceof FieldsPair<?, ?> sp) {
								// ì¬ê·€ì ìœ¼ë¡œ Criteria ìƒì„±
								Criteria sc = createSingleCriteria( sp );
								subCriteriaList.add( sc );

							}

						}

						// subCriteriaListë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
						// $elemMatchëŠ” ë‚´ë¶€ì ìœ¼ë¡œ "ì´ ë°°ì—´ ì›ì†Œ ì¤‘ì—ì„œ ì•„ë˜ Criteriaë“¤ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì›ì†Œ"
						// => typically andOperator
						Criteria subCombined = new Criteria().andOperator( subCriteriaList.toArray( new Criteria[0] ) );
						return criteria.elemMatch( subCombined );

					} else {
						throw new IllegalArgumentException( "Field value must be a collection of FieldsPair<?,?> for 'elemMatch' query type." );

					}

				default:
					throw new IllegalArgumentException( "Unsupported query type: " + queryType );

			}

		} catch (Exception e) {
			throw new RuntimeException( "Failed to create Criteria: " + e.getMessage(), e );

		}

	}

	/**
	 * ì—”í‹°í‹° í´ë˜ìŠ¤ì—ì„œ ì‹ë³„ì(@Id) í•„ë“œë¥¼ ì°¾ëŠ” ë©”ì„œë“œ.
	 * 
	 * @Id ì–´ë…¸í…Œì´ì…˜ì´ ë¶™ì€ í•„ë“œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¾ê³ , ì—†ì„ ê²½ìš° ì´ë¦„ì´ "id"ì¸ í•„ë“œë¥¼ ì°¾ëŠ”ë‹¤.
	 * 
	 * @param entityClass
	 *            ëŒ€ìƒ ì—”í‹°í‹° í´ë˜ìŠ¤
	 * 
	 * @return ì‹ë³„ì í•„ë“œ
	 * 
	 * @throws IllegalArgumentException
	 *             í´ë˜ìŠ¤ ê³„ì¸µ ë‚´ì—ì„œ @Id í•„ë“œë‚˜ ì´ë¦„ì´ "id"ì¸ í•„ë“œë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš°
	 */
	private static Field findIdField(
		Class<?> entityClass
	) {

		// í•„ë“œ ì´ë¦„ì´ "id"ì¸ ê²ƒì„ ì €ì¥í•  ë³€ìˆ˜
		Field idNamedField = null;
		Class<?> currentClass = entityClass;

		// 1. í´ë˜ìŠ¤ ê³„ì¸µì„ ìˆœíšŒí•˜ë©° í•„ë“œë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
		while (currentClass != null && currentClass != Object.class) {

			for (Field field : currentClass.getDeclaredFields()) {

				// @Id ì–´ë…¸í…Œì´ì…˜ì´ ë¶™ì€ í•„ë“œë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ì¦‰ì‹œ ë°˜í™˜í•©ë‹ˆë‹¤.
				if (field.isAnnotationPresent( Id.class )) {
					field.setAccessible( true );
					return field;

				}

				// @Idê°€ ì—†ê³ , ì•„ì§ "id" í•„ë“œë¥¼ ì°¾ì§€ ëª»í–ˆìœ¼ë©°, í˜„ì¬ í•„ë“œ ì´ë¦„ì´ "id"ì¸ ê²½ìš°
				// (ê°€ì¥ í•˜ìœ„ í´ë˜ìŠ¤ì˜ "id" í•„ë“œë¥¼ ì €ì¥í•˜ê¸° ìœ„í•´ idNamedField == null ì¡°ê±´ ì¶”ê°€)
				if (idNamedField == null && "id".equals( field.getName() )) {
					idNamedField = field;

				}

			}

			// ìƒìœ„ í´ë˜ìŠ¤ì—ì„œ í•„ë“œë¥¼ ê³„ì† ì°¾ìŠµë‹ˆë‹¤.
			currentClass = currentClass.getSuperclass();

		}

		// 2. @Id ì–´ë…¸í…Œì´ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, ìˆœíšŒ ì¤‘ ë°œê²¬í–ˆë˜ "id" í•„ë“œê°€ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
		if (idNamedField != null) {
			idNamedField.setAccessible( true );
			return idNamedField;

		}

		// 3. @Id ì–´ë…¸í…Œì´ì…˜ê³¼ "id" í•„ë“œ ëª¨ë‘ ì°¾ì§€ ëª»í•œ ê²½ìš° ì˜ˆì™¸ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.
		throw new IllegalArgumentException(
			"No @Id annotation or 'id' field found in class hierarchy for " + entityClass.getName()
		);

	}


    public ReactiveMongoTemplate getMongoTemplate(K key) {
        return resolver.getTemplate(key);
    }

    public TransactionalOperator getTxOperator(K key) {
        return resolver.getTxOperator(key);
    }

    public <T> Mono<T> getTxJob(K key, Supplier<? extends Mono<? extends T>> supplier) {
        var op = resolver.getTxOperator(key);
        return Mono.defer(supplier).as(op::transactional);
    }


	// íŠ¸ë Œì ì…˜ ì‚¬ìš© ë°©ì‹
	// .flatMap( tuple -> {
	// var account = tuple.getT1();
	// var body = tuple.getT2();
	// mongoQueryBuilder.getMongoTemplate( null );
	// TransactionalOperator transactionalOperator = TransactionalOperator.create(
	// mongoQueryBuilder.getTxManager( MongoTemplateName.FRONT ) );
	// var equipAndUnequip = Mono.defer( () -> {
	// var equipSave = mongoQueryBuilder
	// .executeEntity( UserUnitEntity.class, MongoTemplateName.FRONT )
	// .fields(
	// pair( "accountId", account.getId() ),
	// pair( "id", body.id() )
	// )
	// .end()
	// .find()
	// .execute()
	// .flatMap( e -> {
	// e.setParentUserUnitId( parentUserUnitId );
	// return mongoQueryBuilder
	// .executeEntity( UserUnitEntity.class, MongoTemplateName.FRONT )
	// .save( e );
	//
	// } );
	// var equipDelete = mongoQueryBuilder
	// .executeEntity( UserUnitEntity.class, MongoTemplateName.FRONT )
	// .fields(
	// pair( "accountId", account.getId() ),
	// pair( "prevId", body.id() )
	// )
	// .end()
	// .find()
	// .execute()
	// .flatMap( e -> {
	// e.setParentUserUnitId( null );
	// return mongoQueryBuilder
	// .executeEntity( UserUnitEntity.class, MongoTemplateName.FRONT )
	// .save( e );
	//
	// } );
	// return Mono.zip( equipSave, equipDelete );
	//
	// } );
	// return equipAndUnequip.as( transactionalOperator::transactional );
	//
	// } )

	public enum LogicalOperator {
		AND, OR, NOR
	}

	private static class CriteriaGroup {

		LogicalOperator operator;

		List<Criteria> criteriaList;

		CriteriaGroup(
						LogicalOperator operator
		) {

			this.operator = operator;
			this.criteriaList = new ArrayList<>();

		}

	}


	public abstract class AbstractQueryBuilder<E, T extends AbstractQueryBuilder<E, T>> {

		protected Class<? extends ReactiveCrudRepository<?, ?>> repositoryClass;

		protected ReactiveMongoTemplate reactiveMongoTemplate;

		// protected Mono<Query> queryMono;

		protected Mono<Class<E>> executeClassMono;

		protected String collectionName;

		protected FieldBuilder<E> fieldBuilder = new FieldBuilder<>( LogicalOperator.AND );

		protected AbstractQueryBuilder<E, T> executeBuilder;

		protected ReadPreference readPreference = null;

		protected boolean isAllowDiskUse = false;

		public AbstractQueryBuilder<E, T> readPreference(
			ReadPreference rp
		) {

			this.readPreference = rp;
			return this;

		}

		public AbstractQueryBuilder<E, T> isAllowDiskUse(
			Boolean allow
		) {

			this.isAllowDiskUse = allow == null ? false : allow;
			return this;

		}

		protected Aggregation applyAggOptions(
			Aggregation agg
		) {

			if (readPreference != null || isAllowDiskUse) {
				return agg
					.withOptions(
						AggregationOptions
							.builder()
							.allowDiskUse( isAllowDiskUse )
							.readPreference( readPreference ) // nullì´ë©´ ë¬´ì‹œë¨
							.build()
					);

			}

			return agg
				.withOptions(
					Aggregation
						.newAggregationOptions()
						.allowDiskUse( isAllowDiskUse )
						.build()
				);

		}

		// ğŸ”¹ ê³µí†µ í—¬í¼: Query ì˜µì…˜ ì ìš©
		protected Query applyQueryOptions(
			Query q
		) {

			if (readPreference != null)
				q.withReadPreference( readPreference );
			return q;

		}

		public Mono<E> save(
			E e
		) {

			return reactiveMongoTemplate.save( e );

		}

		public Mono<E> save(
			Mono<E> e
		) {

			return reactiveMongoTemplate.save( e );

		}

		public Flux<E> saveAll(
			Iterable<E> entities
		) {

			return saveAll(
				Flux
					.fromIterable( entities )
			);

		}

		public Flux<E> saveAll(
			Collection<E> entities
		) {

			return saveAll(
				Flux
					.fromIterable( entities )
			);

		}

		public Flux<E> saveAll(
			Flux<E> entityFlux
		) {

			return entityFlux.flatMap( entity -> reactiveMongoTemplate.save( entity ) );

		}


		/**
		 * Iterable<E>ë¥¼ ë°›ì•„ ëŒ€ëŸ‰ ì‚½ì…(Bulk Insert)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
		 * 
		 * @param entities
		 *            ì €ì¥í•  ì—”í‹°í‹° ì»¬ë ‰ì…˜
		 * 
		 * @return ì €ì¥ëœ ì—”í‹°í‹°ì˜ Flux
		 */
		public Flux<E> saveAllBulk(
			Iterable<E> entities
		) {

			return saveAllBulk( Flux.fromIterable( entities ) );

		}

		/**
		 * Collection<E>ë¥¼ ë°›ì•„ ëŒ€ëŸ‰ ì‚½ì…(Bulk Insert)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
		 * 
		 * @param entities
		 *            ì €ì¥í•  ì—”í‹°í‹° ì»¬ë ‰ì…˜
		 * 
		 * @return ì €ì¥ëœ ì—”í‹°í‹°ì˜ Flux
		 */
		public Flux<E> saveAllBulk(
			Collection<E> entities
		) {

			return saveAllBulk( Flux.fromIterable( entities ) );

		}

		/**
		 * Flux<E> ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„ ëŒ€ëŸ‰ ì‚½ì…(Bulk Insert)ì„ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ë©”ì„œë“œì…ë‹ˆë‹¤.
		 * ìŠ¤íŠ¸ë¦¼ì˜ ëª¨ë“  ì—”í‹°í‹°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë‹¨ì¼ DB ìš”ì²­ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
		 * 
		 * @param entityFlux
		 *            ì €ì¥í•  ì—”í‹°í‹°ì˜ Flux
		 * 
		 * @return ì €ì¥ëœ ì—”í‹°í‹°ì˜ Flux
		 */
		public Flux<E> saveAllBulk(
			Flux<E> entityFlux
		) {

			return entityFlux
				.collectList()
				.flatMapMany( list -> {

					if (list.isEmpty()) { return Flux.empty(); }

					return reactiveMongoTemplate.insertAll( list );

				} );

		}

		/**
		 * ì—”í‹°í‹° í•œ ê°œë¥¼ BulkOperationsì— ë°˜ì˜í•˜ëŠ” ê³µí†µ ì²˜ë¦¬
		 */
		private void applyBulkForEntity(
			E entity, Field idField, ReactiveBulkOperations bulkOps
		)
			throws IllegalAccessException {

			Object id = idField.get( entity );

			if (id == null) {
				// ì‹ ê·œ ë ˆì½”ë“œëŠ” insert
				bulkOps.insert( entity );
				return;

			}

			// ê¸°ì¡´ ë ˆì½”ë“œëŠ” upsert
			Query query = Query.query( Criteria.where( "_id" ).is( id ) );

			// Documentë¡œ ë³€í™˜ í›„ _id ì œê±°
			org.bson.Document doc = new org.bson.Document();
			reactiveMongoTemplate.getConverter().write( entity, doc );
			doc.remove( "_id" );

			if (! doc.isEmpty()) {
				org.bson.Document updateDoc = new org.bson.Document( "$set", doc );
				Update update = new BasicUpdate( updateDoc );
				bulkOps.upsert( query, update );

			}

		}
		/**
		 * Iterable<E>ë¥¼ ë°›ì•„ ëŒ€ëŸ‰ ì €ì¥(Bulk Upsert)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
		 * 
		 * @param entities
		 *            ì €ì¥í•  ì—”í‹°í‹° ì»¬ë ‰ì…˜
		 * 
		 * @return BulkWriteResultì˜ Mono
		 */
		public Mono<BulkWriteResult> saveAllBulkUpsert(
			Iterable<E> entities
		) {

			Objects.requireNonNull( entities, "entities must not be null" );

			// ë¹„ì–´ ìˆìœ¼ë©´ ë°”ë¡œ ì¢…ë£Œ
			Iterator<E> it = entities.iterator();

			if (! it.hasNext()) { return Mono.empty(); }

			// ì²« ë²ˆì§¸ ì—”í‹°í‹°ë¡œë¶€í„° íƒ€ì…/ID í•„ë“œ ì •ë³´ ì¶”ì¶œ
			E first = it.next();
			Class<?> entityClass = first.getClass();
			Field idField = findIdField( entityClass );
			idField.setAccessible( true );

			ReactiveBulkOperations bulkOps = reactiveMongoTemplate
				.bulkOps(
					BulkOperations.BulkMode.UNORDERED,
					entityClass
				);

			try {
				// ì²« ë²ˆì§¸ ì—”í‹°í‹° ì²˜ë¦¬
				applyBulkForEntity( first, idField, bulkOps );

				// ë‚˜ë¨¸ì§€ ì—”í‹°í‹° ì²˜ë¦¬
				while (it.hasNext()) {
					E entity = it.next();
					applyBulkForEntity( entity, idField, bulkOps );

				}

			} catch (IllegalAccessException e) {
				return Mono
					.error(
						new RuntimeException( "Failed to access @Id field via reflection", e )
					);

			} finally {
				idField.setAccessible( false );

			}

			return bulkOps.execute();

		}

		/**
		 * Collection<E>ë¥¼ ë°›ì•„ ëŒ€ëŸ‰ ì €ì¥(Bulk Upsert)ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
		 * 
		 * @param entities
		 *            ì €ì¥í•  ì—”í‹°í‹° ì»¬ë ‰ì…˜
		 * 
		 * @return BulkWriteResultì˜ Mono
		 */
		public Mono<BulkWriteResult> saveAllBulkUpsert(
			Collection<E> entities
		) {

			return saveAllBulkUpsert( (Iterable<E>) entities );

		}

		/**
		 * Flux<E> ìŠ¤íŠ¸ë¦¼ì„ ë°›ì•„ ëŒ€ëŸ‰ ì €ì¥(Bulk Upsert)ì„ ìˆ˜í–‰í•˜ëŠ” í•µì‹¬ ë©”ì„œë“œì…ë‹ˆë‹¤.
		 * ìŠ¤íŠ¸ë¦¼ì˜ ëª¨ë“  ì—”í‹°í‹°ì— ëŒ€í•´ 'upsert' ì—°ì‚°ì„ ì¤€ë¹„í•˜ê³  ë‹¨ì¼ DB ìš”ì²­ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.
		 * (ì£¼ì˜: ì´ ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ ì—”í‹°í‹°ì— getId() ë©”ì„œë“œê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.)
		 * 
		 * @param entityFlux
		 *            ì €ì¥í•  ì—”í‹°í‹°ì˜ Flux
		 * 
		 * @return BulkWriteResultì˜ Mono (ì²˜ë¦¬ ê²°ê³¼)
		 */
		public Mono<BulkWriteResult> saveAllBulkUpsert(
			Flux<E> entityFlux
		) {

			AtomicReference<ReactiveBulkOperations> bulkRef = new AtomicReference<>();
			AtomicReference<Field> idFieldRef = new AtomicReference<>();
			AtomicBoolean hasValue = new AtomicBoolean( false );

			return entityFlux
				.flatMap( entity -> {
					hasValue.set( true );

					ReactiveBulkOperations bulkOps = bulkRef.get();
					Field idField = idFieldRef.get();

					// ì²« ìš”ì†Œì—ì„œ lazy init
					if (bulkOps == null) {
						Class<?> entityClass = entity.getClass();
						Field f = findIdField( entityClass );
						f.setAccessible( true );

						ReactiveBulkOperations newBulk = reactiveMongoTemplate
							.bulkOps( BulkOperations.BulkMode.UNORDERED, entityClass );

						bulkRef.set( newBulk );
						idFieldRef.set( f );

						bulkOps = newBulk;
						idField = f;

					}

					try {
						Object id = idField.get( entity );

						if (id == null) {
							// ì‹ ê·œ ë ˆì½”ë“œ â†’ insert
							bulkOps.insert( entity );
							return Mono.empty();

						}

						Query query = Query.query( Criteria.where( "_id" ).is( id ) );

						org.bson.Document doc = new org.bson.Document();
						reactiveMongoTemplate.getConverter().write( entity, doc );
						doc.remove( "_id" );

						if (! doc.isEmpty()) {
							org.bson.Document updateDoc = new org.bson.Document( "$set", doc );
							Update update = new BasicUpdate( updateDoc );
							bulkOps.upsert( query, update );

						}

						return Mono.empty();

					} catch (IllegalAccessException e) {
						return Mono
							.error(
								new RuntimeException( "Failed to access @Id field via reflection", e )
							);

					}

				} )
				// ëª¨ë“  ì—”í‹°í‹°ì— ëŒ€í•´ bulk ì‘ì—… ìŒ“ê¸° ëë‚œ ë’¤ execute
				.then(
					Mono.defer( () -> {

						if (! hasValue.get()) {
							// ë¹„ì–´ìˆëŠ” Flux ì˜€ìœ¼ë©´ ì•„ë¬´ ì‘ì—…ë„ ì•ˆ í•¨
							return Mono.empty();

						}

						ReactiveBulkOperations bulkOps = bulkRef.get();

						if (bulkOps == null) { return Mono.empty(); }

						return bulkOps.execute();

					} )
				)
				// ì„±ê³µ/ì‹¤íŒ¨/ì·¨ì†Œ ì–´ë–¤ ê²½ìš°ë“  @Id í•„ë“œ ì ‘ê·¼ ê¶Œí•œ ì›ë³µ
				.doFinally( signalType -> {
					Field idField = idFieldRef.get();

					if (idField != null) {
						idField.setAccessible( false );

					}

				} );

		}

		public Mono<BulkWriteResult> saveAllBulkUpsertByKey(
			Flux<E> entityFlux, String... keyFieldName // ì˜ˆ: "caseKey" ë˜ëŠ” "court","year","caseNo"
		) {

			if (entityFlux == null)
				return Mono.error( new IllegalArgumentException( "entityFlux must not be null" ) );
			if (keyFieldName == null || keyFieldName.length == 0)
				return Mono.error( new IllegalArgumentException( "keyFieldName must not be null/empty" ) );

			// blank ë°©ì§€ + ì •ê·œí™”
			final String[] keys = Arrays
				.stream( keyFieldName )
				.filter( Objects::nonNull )
				.map( String::trim )
				.filter( s -> ! s.isBlank() )
				.toArray( String[]::new );

			if (keys.length == 0)
				return Mono.error( new IllegalArgumentException( "keyFieldName must contain at least 1 non-blank field" ) );

			AtomicReference<ReactiveBulkOperations> bulkRef = new AtomicReference<>();
			AtomicReference<Field[]> keyFieldsRef = new AtomicReference<>();
			AtomicBoolean hasValue = new AtomicBoolean( false );

			return entityFlux
				// bulkOpsì— ì‘ì—… ìŒ“ê¸°ëŠ” side-effect -> ìˆœì°¨ë¡œ ì•ˆì „í•˜ê²Œ
				.concatMap( entity -> {
					hasValue.set( true );

					ReactiveBulkOperations bulkOps = bulkRef.get();
					Field[] keyFields = keyFieldsRef.get();

					// ì²« ìš”ì†Œì—ì„œ lazy init
					if (bulkOps == null) {
						Class<?> entityClass = entity.getClass();

						Field[] fs = new Field[keys.length];

						try {

							for (int i = 0; i < keys.length; i++) {
								Field f = entityClass.getDeclaredField( keys[i] );
								f.setAccessible( true );
								fs[i] = f;

							}

						} catch (NoSuchFieldException e) {
							return Mono
								.error(
									new IllegalArgumentException(
										"No field in " + entityClass.getName() + ": " + e.getMessage(),
										e
									)
								);

						}

						ReactiveBulkOperations newBulk = reactiveMongoTemplate.bulkOps( BulkOperations.BulkMode.UNORDERED, entityClass );

						bulkRef.set( newBulk );
						keyFieldsRef.set( fs );

						bulkOps = newBulk;
						keyFields = fs;

					}

					try {
						// keyDoc êµ¬ì„± + null ì²´í¬
						Document keyDoc = new Document();

						for (int i = 0; i < keys.length; i++) {
							Object v = keyFields[i].get( entity );

							if (v == null) {
								// ì •ì±…: í‚¤ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ upsert ë¶ˆê°€ -> insert(ë˜ëŠ” skip/ì—ëŸ¬ë¡œ ë°”ê¿”ë„ ë¨)
								bulkOps.insert( entity );
								return Mono.empty();

							}

							keyDoc.append( keys[i], v );

						}

						// Query: ë‹¨ì¼í‚¤ë©´ where, ë³µí•©í‚¤ë©´ andOperator
						Query query;

						if (keys.length == 1) {
							query = Query.query( Criteria.where( keys[0] ).is( keyDoc.get( keys[0] ) ) );

						} else {
							Criteria[] cs = new Criteria[keys.length];

							for (int i = 0; i < keys.length; i++) {
								cs[i] = Criteria.where( keys[i] ).is( keyDoc.get( keys[i] ) );

							}

							query = Query.query( new Criteria().andOperator( cs ) );

						}

						// Update: ì—”í‹°í‹° -> doc ë³€í™˜ í›„ _id ì œê±°
						Document doc = new Document();
						reactiveMongoTemplate.getConverter().write( entity, doc );
						doc.remove( "_id" );

						Document updateDoc = new Document()
							.append( "$set", new Document( doc ) )
							.append( "$setOnInsert", new Document( keyDoc ) ); // í‚¤ í•„ë“œë“¤ ê³ ì •

						bulkOps.upsert( query, new BasicUpdate( updateDoc ) );
						return Mono.empty();

					} catch (IllegalAccessException e) {
						return Mono.error( new RuntimeException( "Failed to access key field(s)", e ) );

					}

				} )
				.then( Mono.defer( () -> {
					if (! hasValue.get())
						return Mono.empty();
					ReactiveBulkOperations bulkOps = bulkRef.get();
					if (bulkOps == null)
						return Mono.empty();
					return bulkOps.execute();

				} ) )
				.doFinally( st -> {
					Field[] fs = keyFieldsRef.get();

					if (fs != null) {

						for (Field f : fs) {
							if (f != null)
								f.setAccessible( false );

						}

					}

				} );
		}


		public Mono<BulkWriteResult> saveAllBulkUpsertByKey(
			Collection<E> entities, String... keyFieldName // ì˜ˆ: "caseKey" ë˜ëŠ” "court", "year", "caseNo"
		) {

			if (entities == null || entities.isEmpty())
				return Mono.empty();
			if (keyFieldName == null || keyFieldName.length == 0)
				return Mono.error( new IllegalArgumentException( "keyFieldName must not be null/empty" ) );

			// blank ë°©ì§€
			String[] keys = Arrays
				.stream( keyFieldName )
				.filter( Objects::nonNull )
				.map( String::trim )
				.filter( s -> ! s.isBlank() )
				.toArray( String[]::new );

			if (keys.length == 0)
				return Mono.error( new IllegalArgumentException( "keyFieldName must contain at least 1 non-blank field" ) );

			Class<?> entityClass = entities.iterator().next().getClass();

			// key Fieldë“¤ ì¤€ë¹„
			final Field[] keyFields = new Field[keys.length];

			try {

				for (int i = 0; i < keys.length; i++) {
					Field f = entityClass.getDeclaredField( keys[i] );
					f.setAccessible( true );
					keyFields[i] = f;

				}

			} catch (NoSuchFieldException e) {
				// ì–´ë–¤ í‚¤ì—ì„œ í„°ì¡ŒëŠ”ì§€ ë©”ì‹œì§€ ë³´ê°•
				return Mono.error( new IllegalArgumentException( "No field in " + entityClass.getName() + ": " + e.getMessage(), e ) );

			}

			ReactiveBulkOperations bulkOps = reactiveMongoTemplate.bulkOps( BulkOperations.BulkMode.UNORDERED, entityClass );

			try {

				for (E entity : entities) {

					// 1) key ê°’ ìˆ˜ì§‘ + null ì²´í¬
					Document keyDoc = new Document(); // {k1:v1, k2:v2...} (setOnInsertì—ë„ ì¬ì‚¬ìš©)
					boolean missingKey = false;

					for (int i = 0; i < keys.length; i++) {
						Object v = keyFields[i].get( entity );

						if (v == null) {
							missingKey = true;
							break;

						}

						keyDoc.append( keys[i], v );

					}

					if (missingKey) {
						// ì •ì±…: í‚¤ê°€ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ upsert ê¸°ì¤€ì´ ì—†ìœ¼ë‹ˆ insert(ë˜ëŠ” skip/ì—ëŸ¬) ì¤‘ íƒ1
						bulkOps.insert( entity );
						continue;

					}

					// 2) Query: AND ì¡°ê±´ìœ¼ë¡œ ê²°í•© (ë³µí•©í‚¤)
					Criteria[] cs = new Criteria[keys.length];

					for (int i = 0; i < keys.length; i++) {
						cs[i] = Criteria.where( keys[i] ).is( keyDoc.get( keys[i] ) );

					}

					Query query = Query.query( new Criteria().andOperator( cs ) );

					// 3) Update document ìƒì„±
					Document doc = new Document();
					reactiveMongoTemplate.getConverter().write( entity, doc );
					doc.remove( "_id" ); // _idëŠ” ê¸°ë³¸ ìƒì„± ìœ ì§€
					for (String k : keys) {
						doc.remove(k);
					}

					// ì—…ë°ì´íŠ¸ëŠ” $set, í‚¤ëŠ” ë¶ˆë³€ ê°€ì •ì´ë©´ $setOnInsertë¡œë§Œ
					Document updateDoc = new Document()
						.append( "$set", new Document( doc ) )
						.append( "$setOnInsert", new Document( keyDoc ) ); // keyë“¤ ì „ë¶€ ë„£ê¸°

					bulkOps.upsert( query, new BasicUpdate( updateDoc ) );

				}

			} catch (IllegalAccessException e) {
				return Mono.error( new RuntimeException( "Failed to access key field(s)", e ) );

			} finally {

				for (Field f : keyFields) {
					if (f != null)
						f.setAccessible( false );

				}

			}

			return bulkOps.execute();

		}
		private String resolveRemoveCollectionName(
			Class<?> clazz
		) {

			var doc = clazz
				.getDeclaredAnnotation(
					org.springframework.data.mongodb.core.mapping.Document.class
				);

			if (doc == null || doc.collection() == null || doc.collection().isBlank()) { return clazz.getSimpleName() + "_remove"; }

			return doc.collection() + "_remove";

		}

		public Mono<BulkWriteResult> deleteBulk(
			Iterable<E> entities
		) {

			return deleteBulk( Flux.fromIterable( entities ), false );

		}

		public Mono<BulkWriteResult> deleteBulk(
			Iterable<E> entities, boolean isBackup
		) {

			return deleteBulk( Flux.fromIterable( entities ), isBackup );

		}

		public Mono<BulkWriteResult> deleteBulk(
			Collection<E> entities
		) {

			return deleteBulk( Flux.fromIterable( entities ), false );

		}

		public Mono<BulkWriteResult> deleteBulk(
			Collection<E> entities, boolean isBackup
		) {

			return deleteBulk( Flux.fromIterable( entities ), isBackup );

		}

		public Mono<BulkWriteResult> deleteBulk(
			Flux<E> entityFlux
		) {

			return deleteBulk( entityFlux, false );

		}

		public Mono<BulkWriteResult> deleteBulk(
			Flux<E> entityFlux, boolean isBackup
		) {

			if (! isBackup) { return deleteBulkInternal( entityFlux ); }

			// backupì´ í•„ìš”í•œ ê²½ìš°ì—” ì—”í‹°í‹°ë¥¼ ì¬ì‚¬ìš©í•´ì•¼ í•˜ë¯€ë¡œ listë¡œ í•œë²ˆ ëª¨ìŒ
			return entityFlux
				.collectList()
				.flatMap( list -> {

					if (list.isEmpty())
						return Mono.empty();

					Class<?> entityClass = list.get( 0 ).getClass();
					String backupCollectionName = resolveRemoveCollectionName( entityClass );

					// ë°±ì—… ë¨¼ì € ì ì¬ -> ê·¸ ë‹¤ìŒ bulk delete
					return reactiveMongoTemplate
						.insert( list, backupCollectionName )
						.then( deleteBulkInternal( Flux.fromIterable( list ) ) );

				} );

		}

		/**
		 * ì‹¤ì œ bulk delete ìˆ˜í–‰(backup ì—†ì´).
		 * saveAllBulkUpsert(Flux)ì™€ ë™ì¼í•œ lazy-init íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
		 */
		private Mono<BulkWriteResult> deleteBulkInternal(
			Flux<E> entityFlux
		) {

			AtomicReference<ReactiveBulkOperations> bulkRef = new AtomicReference<>();
			AtomicReference<Field> idFieldRef = new AtomicReference<>();
			AtomicBoolean hasValue = new AtomicBoolean( false );

			return entityFlux
				.flatMap( entity -> {

					hasValue.set( true );

					ReactiveBulkOperations bulkOps = bulkRef.get();
					Field idField = idFieldRef.get();

					// ì²« ìš”ì†Œì—ì„œ lazy init
					if (bulkOps == null) {
						Class<?> entityClass = entity.getClass();

						Field f = findIdField( entityClass );
						f.setAccessible( true );

						ReactiveBulkOperations newBulk = reactiveMongoTemplate
							.bulkOps( BulkOperations.BulkMode.UNORDERED, entityClass );

						bulkRef.set( newBulk );
						idFieldRef.set( f );

						bulkOps = newBulk;
						idField = f;

					}

					try {
						Object id = idField.get( entity );

						// id ì—†ìœ¼ë©´ ì‚­ì œ ëŒ€ìƒì—ì„œ ì œì™¸
						if (id == null)
							return Mono.empty();

						Query q = Query.query( Criteria.where( "_id" ).is( id ) );
						bulkOps.remove( q );

						return Mono.empty();

					} catch (IllegalAccessException e) {
						return Mono.error( new RuntimeException( "Failed to access @Id field via reflection", e ) );

					}

				} )
				.then(
					Mono.defer( () -> {

						if (! hasValue.get())
							return Mono.empty();

						ReactiveBulkOperations bulkOps = bulkRef.get();
						if (bulkOps == null)
							return Mono.empty();

						return bulkOps.execute();

					} )
				)
				.doFinally( signalType -> {
					Field idField = idFieldRef.get();
					if (idField != null)
						idField.setAccessible( false );

				} );

		}
		
		public Mono<DeleteResult> delete(
			E e
		) {

			return this.delete( e, false );

		}

		public Mono<DeleteResult> delete(
			Mono<E> e
		) {

			return this.delete( e, false );

		}

		public Mono<DeleteResult> delete(
			E e, boolean isBackup
		) {

			return reactiveMongoTemplate
				.remove( e )
				.flatMap( dr -> {

					if (! isBackup) { return Mono.just( dr ); }

					return executeClassMono.flatMap( clazz -> {
						var doc = clazz
							.getDeclaredAnnotation(
								org.springframework.data.mongodb.core.mapping.Document.class
							);

						String collectionName;

						if (doc == null || doc.collection() == null || doc.collection().isBlank()) {
							collectionName = clazz.getSimpleName() + "_remove";

						} else {
							collectionName = doc.collection() + "_remove";

						}

						// ë°±ì—… insert ì™„ë£Œ í›„ ì›ë˜ DeleteResultë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
						return reactiveMongoTemplate.insert( e, collectionName ).thenReturn( dr );

					} );

				} );

		}


		public Mono<DeleteResult> delete(
			Mono<E> eMono, boolean isBackup
		) {

			return eMono
				.flatMap(
					entity -> reactiveMongoTemplate
						.remove( entity )
						.flatMap( dr -> {
							if (! isBackup)
								return Mono.just( dr );

							return executeClassMono.flatMap( clazz -> {
								var doc = clazz.getDeclaredAnnotation( org.springframework.data.mongodb.core.mapping.Document.class );
								String collectionName;

								if (doc == null || doc.collection() == null || doc.collection().isBlank()) {
									collectionName = clazz.getSimpleName() + "_remove";

								} else {
									collectionName = doc.collection() + "_remove";

								}

								// ë°±ì—… insert ì™„ë£Œ í›„ ì›ë˜ DeleteResultë¥¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
								return reactiveMongoTemplate.insert( entity, collectionName ).thenReturn( dr );

							} );

						} )
				);

		}
		
		@SuppressWarnings("unchecked")
		private E deepClone(E e, ObjectMapper objectMapper) {
		    try {
		        String json = objectMapper.writeValueAsString(e);
		        return (E) objectMapper.readValue(json, e.getClass());
		    } catch (Exception ex) {
		        throw new RuntimeException("Failed to clone entity for history", ex);
		    }
		}

		public Mono<Void> createHistory(
			E e
		) {

			return createHistory( e, "history", objectMapper );

		}

		public Mono<Void> createHistory(
			E e, String prefix
		) {

			return createHistory( e, prefix, objectMapper );

		}

		public Mono<Void> createHistory(
			E e, ObjectMapper objectMapper
		) {

			return createHistory( e, "history", objectMapper );

		}

		public Mono<Void> createHistory(
			E e, String prefix, ObjectMapper objectMapper
		) {

			Class<?> entityClass = e.getClass();
			String _prefix = (prefix == null || prefix.isBlank())
				? "history"
				: (prefix.charAt( 0 ) == '_' ? prefix.substring( 1 ) : prefix);

			String base;

			if (! entityClass.isAnnotationPresent( org.springframework.data.mongodb.core.mapping.Document.class )) {
				base = entityClass.getSimpleName();

			} else {
				var doc = entityClass.getAnnotation( org.springframework.data.mongodb.core.mapping.Document.class );
				String cand = ! doc.collection().isBlank() ? doc.collection() : doc.value();
				base = cand.isBlank() ? entityClass.getSimpleName() : cand;

			}

			String backupCollectionName = base + "_" + _prefix;

			E snapshot = deepClone(e, objectMapper);

			MongoMappingContext ctx = (MongoMappingContext) reactiveMongoTemplate.getConverter().getMappingContext();
			MongoPersistentEntity<?> pe = ctx.getPersistentEntity( snapshot.getClass() );
			boolean idCleared = false;

			if (pe != null && pe.getIdProperty() != null) {
				PersistentPropertyAccessor<?> accessor = pe.getPropertyAccessor( snapshot );
				MongoPersistentProperty idProp = pe.getIdProperty();
				accessor.setProperty( idProp, null );
				idCleared = true;

			}

			if (! idCleared) {
				Class<?> c = snapshot.getClass();

				while (c != null && c != Object.class) {

					try {
						var f = c.getDeclaredField( "id" );
						f.setAccessible( true );
						f.set( snapshot, null );
						break;

					} catch (NoSuchFieldException ignore) {
						c = c.getSuperclass();

					} catch (IllegalAccessException ignore) {
						break;

					}

				}

			}

			return reactiveMongoTemplate.insert( snapshot, backupCollectionName ).then();

		}

		public FieldBuilder<E> fields(
			FieldsPair<?, ?>... fieldsPairs
		) {

			return fields( LogicalOperator.AND, fieldsPairs );

		}

		public FieldBuilder<E> fields(
			Collection<FieldsPair<?, ?>> fieldsPairs
		) {

			return fields( LogicalOperator.AND, fieldsPairs );

		}

		public FieldBuilder<E> fields() {

			return fields( LogicalOperator.AND );

		}


		public FieldBuilder<E> fields(
			LogicalOperator logicalOperator, FieldsPair<?, ?>... fieldsPairs
		) {

			if (fieldsPairs == null || fieldsPairs.length == 0)
				return createFirstOperator( logicalOperator );
			return createFirstOperator( logicalOperator ).fields( fieldsPairs );

		}

		public FieldBuilder<E> fields(
			LogicalOperator logicalOperator, Collection<FieldsPair<?, ?>> fieldsPairs
		) {

			if (fieldsPairs == null || fieldsPairs.isEmpty())
				return createFirstOperator( logicalOperator );
			return createFirstOperator( logicalOperator ).fields( fieldsPairs.stream().toArray( FieldsPair[]::new ) );

		}

		public FieldBuilder<E> fields(
			LogicalOperator logicalOperator
		) {

			return createFirstOperator( logicalOperator );

		}

		private FieldBuilder<E> createFirstOperator(
			LogicalOperator logicalOperator
		) {

			this.fieldBuilder = new FieldBuilder<>( logicalOperator );
			return this.fieldBuilder;

		}

		protected Mono<Class<E>> extractEntityClass(
			Class<? extends ReactiveCrudRepository<?, ?>> repositoryClass
		) {

			@SuppressWarnings("unchecked")
			Class<E> cachedClass = (Class<E>) entityClassCache.get( repositoryClass );

			if (cachedClass != null) { return Mono.just( cachedClass ); }

			@SuppressWarnings("unchecked")
			Mono<Class<E>> result = Mono.fromCallable( () -> {
				// ë¦¬í¬ì§€í† ë¦¬ í´ë˜ìŠ¤ê°€ ReactiveCrudRepositoryë¥¼ êµ¬í˜„í•˜ê³  ìˆëŠ”ì§€ í™•ì¸
				Type[] genericInterfaces = repositoryClass.getGenericInterfaces();
				ParameterizedType reactiveCrudRepoType = null;

				for (Type type : genericInterfaces) {

					if (type instanceof ParameterizedType) {
						ParameterizedType paramType = (ParameterizedType) type;

						if (paramType.getRawType() instanceof Class && ReactiveCrudRepository.class.isAssignableFrom( (Class<?>) paramType.getRawType() )) {
							reactiveCrudRepoType = paramType;
							break;

						}

					}

				}

				// ReactiveCrudRepository ì¸í„°í˜ì´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ì˜ˆì™¸ ë°œìƒ
				if (reactiveCrudRepoType == null) {
					throw new IllegalArgumentException(
						"The provided repository class '" + repositoryClass.getName() + "' does not implement ReactiveCrudRepository."
					);

				}

				// ì²« ë²ˆì§¸ ì œë„ˆë¦­ íƒ€ì… ì¸ìˆ˜(T)ë¥¼ ì¶”ì¶œ
				Type entityType = reactiveCrudRepoType.getActualTypeArguments()[0];

				if (! (entityType instanceof Class<?>)) { throw new IllegalArgumentException(
					"The entity type is not a class for repository '" + repositoryClass.getName() + "'."
				); }

				Class<?> entityClass = (Class<?>) entityType;

				// ì—”í‹°í‹° í´ë˜ìŠ¤ê°€ BaseEntityë¥¼ ìƒì†í•˜ëŠ”ì§€ í™•ì¸
//				if (! BaseEntity.class.isAssignableFrom( entityClass )) { throw new IllegalArgumentException(
//					"The entity class '" + entityClass.getName() + "' must extend 'BaseEntity'."
//				); }

				return (Class<E>) entityClass;

			} );
			return result;// .onErrorMap( e -> new RuntimeException( "Failed to extract entity class: " + e.getMessage(), e )
							// );

		}

		public abstract class Grouping<KK, V> {

			private final List<String> keyFields = new ArrayList<>();

			private final Document accumulators = new Document(); // as -> {$op: ...}

			private boolean hasAccumulator = false; // ì•„ë¬´ê²ƒë„ ì§€ì • ì•ˆ í•˜ë©´ count ê¸°ë³¸

			protected Class<KK> keyType;

			protected Class<V> valueType;

			private Function<Document, KK> keyConverter;

			private Function<Document, V> valueConverter;

			@SuppressWarnings("unchecked")
			public Grouping(
							Class<KK> k,
							Class<V> v
			) {

				this.keyType = k;
				this.valueType = v;

				this.keyConverter = (Document kk) -> {
					Object key = kk.get( "_id" );

					return (KK) key;

				};
				this.valueConverter = (Document vv) -> {

					return reactiveMongoTemplate.getConverter().read( this.valueType, vv );

				};

			}
			// @SuppressWarnings("unchecked")
			// public Grouping() {
			//
			// Type genericSuperclass = getClass().getGenericSuperclass();
			//
			// if (! (genericSuperclass instanceof ParameterizedType)) {
			// // ìƒì„¸í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ìƒì„±
			//
			// throw new IllegalStateException(
			// String
			// .format(
			// "Class '%s' inherits from Grouping without specifying generic parameters. " + "To check type
			// information at runtime, you must inherit using the format 'extends Grouping<ConcreteKeyType,
			// ConcreteValueType>'.",
			// getClass().getName()
			// )
			// );
			//
			// }
			//
			// ParameterizedType parameterizedType = (ParameterizedType) genericSuperclass;
			// Type[] typeArguments = parameterizedType.getActualTypeArguments();
			//
			// System.out.println( Arrays.asList( typeArguments ) );
			//
			// this.keyType = (Class<K>) typeArguments[0];
			// this.valueType = (Class<V>) typeArguments[1];
			//
			// this.keyConverter = (Document kk) -> {
			// Object key = kk.get( "_id" );
			//
			// return (K) key;
			//
			// };
			// this.valueConverter = (Document vv) -> {
			//
			// return reactiveMongoTemplate.getConverter().read( this.valueType, vv );
			//
			// };
			//
			// }

			public Grouping<KK, V> keyConverter(
				Function<Document, KK> fn
			) {

				if (fn != null) {
					this.keyConverter = fn;

				}

				return this;

			}

			public Grouping<KK, V> valueConverter(
				Function<Document, V> fn
			) {

				if (fn != null) {
					this.valueConverter = fn;

				}

				return this;

			}

			/** ê·¸ë£¹ í‚¤ ì§€ì • (1ê°œ ì´ìƒ) */
			public Grouping<KK, V> by(
				String... keys
			) {

				if (keys == null || keys.length == 0) { throw new IllegalArgumentException( "group by keys must not be empty." ); }

				for (String k : keys) {
					if (k == null || k.isBlank())
						continue;
					keyFields.add( k );

				}

				if (keyFields.isEmpty()) { throw new IllegalArgumentException( "valid group by key required." ); }

				return this;

			}

			/** ëˆ„ì ê¸°ë“¤ */
			public Grouping<KK, V> count() {

				return countAs( "count" );

			}

			public Grouping<KK, V> countAs(
				String as
			) {

				accumulators.put( as, new Document( "$sum", 1 ) );
				hasAccumulator = true;
				return this;

			}

			public Grouping<KK, V> sum(
				String field, String as
			) {

				accumulators.put( as, new Document( "$sum", "$" + field ) );
				hasAccumulator = true;
				return this;

			}

			public Grouping<KK, V> avg(
				String field, String as
			) {

				accumulators.put( as, new Document( "$avg", "$" + field ) );
				hasAccumulator = true;
				return this;

			}

			public Grouping<KK, V> min(
				String field, String as
			) {

				accumulators.put( as, new Document( "$min", "$" + field ) );
				hasAccumulator = true;
				return this;

			}

			public Grouping<KK, V> max(
				String field, String as
			) {

				accumulators.put( as, new Document( "$max", "$" + field ) );
				hasAccumulator = true;
				return this;

			}

			public Grouping<KK, V> addToSet(
				String field, String as
			) {

				accumulators.put( as, new Document( "$addToSet", "$" + field ) );
				hasAccumulator = true;
				return this;

			}

			public Grouping<KK, V> push(
				String field, String as
			) {

				accumulators.put( as, new Document( "$push", "$" + field ) );
				hasAccumulator = true;
				return this;

			}

			/** lookup ì—†ì´ ê·¸ë£¹ ì‹¤í–‰ */
			public Mono<Map<KK, V>> execute() {

				return buildAndRun( null, null );

			}

			/** lookup í¬í•¨ ê·¸ë£¹ ì‹¤í–‰ */
			public <R2> Mono<Map<KK, V>> executeLookup(
				AbstractQueryBuilder<R2, ?>.FindAllQueryBuilder<R2> rightBuilder, LookupSpec spec
			) {

				Objects.requireNonNull( rightBuilder, "rightBuilder is required" );
				Objects.requireNonNull( spec, "LookupSpec is required" );
				return buildAndRun( new LookupCtx<>( rightBuilder, spec ), null );

			}

			// ë‚´ë¶€: íŒŒì´í”„ë¼ì¸ êµ¬ì„±/ì‹¤í–‰
			private <R2> Mono<Map<KK, V>> buildAndRun(LookupCtx<R2> lookup, Sort dummy) {

			    if (keyFields.isEmpty()) throw new IllegalStateException("group by keys are not specified.");
			    if (!hasAccumulator) count();

			    Mono<Class<E>> leftClassMono = executeClassMono;

			    return Mono.zip(fieldBuilder.buildCriteria(), leftClassMono)
			        .flatMap(tuple -> {
			            Optional<Criteria> leftMatch = tuple.getT1();
			            Class<E> leftClass = tuple.getT2();

			            String leftColl = (collectionName != null && !collectionName.isBlank())
			                ? collectionName
			                : reactiveMongoTemplate.getCollectionName(leftClass);

			            List<AggregationOperation> ops = new ArrayList<>();
			            leftMatch.ifPresent(c -> ops.add(Aggregation.match(c)));

			            Mono<List<AggregationOperation>> opsMono =
			                (lookup == null)
			                    ? Mono.just(ops)
			                    : lookup.rightClass().map(rightClass -> {
			                        String rightColl = (lookup.rightCollectionName() != null && !lookup.rightCollectionName().isBlank())
			                            ? lookup.rightCollectionName()
			                            : reactiveMongoTemplate.getCollectionName(rightClass);

			                        String rightAs = (lookup.spec.as != null && !lookup.spec.as.isBlank())
			                            ? lookup.spec.as
			                            : rightClass.getSimpleName();

			                        Document lk = new Document("from", rightColl).append("as", rightAs);

			                        if (lookup.spec.localField != null && lookup.spec.foreignField != null) {
			                            lk.append("localField", lookup.spec.localField)
			                              .append("foreignField", lookup.spec.foreignField);
			                        } else {
			                            lk.append("let", Optional.ofNullable(lookup.spec.letDoc).orElseGet(Document::new))
			                              .append("pipeline", Optional.ofNullable(lookup.spec.pipelineDocs).orElseGet(List::of));
			                        }

			                        ops.add(ctx -> new Document("$lookup", lk));

			                        if (lookup.spec.unwind) {
			                            ops.add(ctx -> new Document(
			                                "$unwind",
			                                new Document("path", "$" + rightAs)
			                                    .append("preserveNullAndEmptyArrays", lookup.spec.preserveNullAndEmptyArrays)
			                            ));
			                        }

			                        if (lookup.spec.getOuterStages() != null) {
			                            for (Document st : lookup.spec.getOuterStages()) {
			                                ops.add(ctx -> st);
			                            }
			                        }

			                        return ops;
			                    });

			            return opsMono.flatMap(opList -> {
			                Object groupId = (keyFields.size() == 1)
			                    ? "$" + keyFields.get(0)
			                    : new Document().append(keyFields.get(0), "$" + keyFields.get(0)); // ì•„ë˜ì—ì„œ ì œëŒ€ë¡œ ì±„ì›€

			                if (keyFields.size() > 1) {
			                    Document gid = new Document();
			                    for (String k : keyFields) gid.append(k, "$" + k);
			                    groupId = gid;
			                }

			                Document groupBody = new Document("_id", groupId);
			                for (String as : accumulators.keySet()) groupBody.append(as, accumulators.get(as));
			                opList.add(ctx -> new Document("$group", groupBody));

			                Aggregation agg = applyAggOptions(Aggregation.newAggregation(opList));

			                Flux<Document> flux = (collectionName != null && !collectionName.isBlank())
			                    ? reactiveMongoTemplate.aggregate(agg, leftColl, Document.class)
			                    : reactiveMongoTemplate.aggregate(agg, leftClass, Document.class);

			                return flux.collect(LinkedHashMap::new, (LinkedHashMap<KK, V> map, Document d) -> {
			                    KK key = this.keyConverter.apply(d);
			                    Document vd = new Document(d);
			                    vd.remove("_id");
			                    V v = this.valueConverter.apply(vd);
			                    map.put(key, v);
			                });
			            });
			        });
			}

			// $lookup ì»¨í…ìŠ¤íŠ¸ Helper
			private class LookupCtx<R2> {

				final AbstractQueryBuilder<R2, ?>.FindAllQueryBuilder<R2> rightBuilder;

				final LookupSpec spec;

				LookupCtx(
							AbstractQueryBuilder<R2, ?>.FindAllQueryBuilder<R2> rb,
							LookupSpec sp
				) {

					this.rightBuilder = rb;
					this.spec = sp;

				}

				Mono<Class<R2>> rightClass() {

					return rightBuilder.getExecuteClassMono();

				}

				String rightCollectionName() {

					return rightBuilder.getCollectionName();

				}

			}

		}

		/**
		 * Encapsulates $lookup specification (from, as, localField/foreignField or let+pipeline).
		 * <p>Usage examples:</p>
		 *
		 * <pre>{@code
		 * 
		 * // í˜„ì¬ ê³„ì • ë³´ìœ  ì—¬ë¶€ ì¡°ì¸ (title â†” accountTitle)
		 * var spec = LookupSpec
		 * 	.builder()
		 * 	.from( "accountTitle" )
		 * 	.as( "ownHit" )
		 * 	// title._id == accountTitle.titleId
		 * 	.bindConditionFields( "_id", Condition.eq, "titleId" )
		 * 	// accountTitle.accountId == accountId
		 * 	.bindConditionConst( accountId, Condition.eq, "accountId" )
		 * 	.limit( 1 )
		 * 	// .unwind(true) // ë‹¨ê±´í™” ì›í•˜ë©´
		 * 	.build();
		 *
		 * // ì´ë¦„ ë¶€ë¶„ ì¼ì¹˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
		 * var spec2 = LookupSpec
		 * 	.builder()
		 * 	.from( "titles" )
		 * 	.as( "matched" )
		 * 	.bindConditionLike( ".*pro.*", "name", "i" )
		 * 	.build();
		 *
		 * // ì¹´í…Œê³ ë¦¬ in (...)
		 * var spec3 = LookupSpec
		 * 	.builder()
		 * 	.from( "titles" )
		 * 	.as( "matched" )
		 * 	.bindConditionConst( List.of( "rpg", "indie" ), Condition.in, "category" )
		 * 	.build();
		 *
		 * // createdAt between
		 * var spec4 = LookupSpec
		 * 	.builder()
		 * 	.from( "accountTitle" )
		 * 	.as( "ownHit" )
		 * 	.bindConditionBetween( startInstant, endInstant, "createdAt" )
		 * 	.build();
		 * }</pre>
		 *
		 * @see LookupSpec.Builder
		 * @see LookupSpec.Builder#from(String)
		 * @see LookupSpec.Builder#as(String)
		 * @see LookupSpec.Builder#bindConditionFields(String, Condition, String)
		 * @see LookupSpec.Builder#bindConditionConst(Object, Condition, String)
		 * @see LookupSpec.Builder#bindConditionBetween(Object, Object, String)
		 * @see LookupSpec.Builder#bindConditionLike(String, String, String)
		 * @see LookupSpec.Builder#unwind(boolean)
		 * @see LookupSpec.Builder#build()
		 */
		public static class LookupSpec {

			// // ìµœì¢… ê²°ê³¼ë¬¼ (executeLookupì—ì„œ ì‚¬ìš©)
			// private String from;
			private List<Document> outerStages = new ArrayList<>();

			public List<Document> getOuterStages() { return outerStages; }

			private String as;

			private String localField;

			private String foreignField;

			private Document letDoc; // ë¹Œë”ê°€ ì¡°ë¦½

			private List<Document> pipelineDocs; // ë¹Œë”ê°€ ì¡°ë¦½

			private boolean unwind;

			private boolean preserveNullAndEmptyArrays;

			private LookupSpec() {}

			// ê²Œí„° (executeLookupì—ì„œ ì ‘ê·¼)
			// public String getFrom() { return from; }

			public String getAs() { return as; }

			public String getLocalField() { return localField; }

			public String getForeignField() { return foreignField; }

			public Document getLetDoc() { return letDoc; }

			public List<Document> getPipelineDocs() { return pipelineDocs; }

			public boolean isUnwind() { return unwind; }

			public boolean isPreserveNullAndEmptyArrays() { return preserveNullAndEmptyArrays; }

			public static Builder builder() {

				return new Builder();

			}

			/**
			 * Fluent builder for constructing {@link LookupSpec} instances.
			 * <p>Provides chainable methods to define <code>from</code>, <code>as</code>, conditions,
			 * pipeline stages, and finally {@link #build()}.</p>
			 * <p>For detailed usage examples, see the Javadoc on {@link LookupSpec}.</p>
			 */
			public static class Builder {

				private List<Document> outerStages = new ArrayList<>(); // â† ì¶”ê°€

				private final LookupSpec spec = new LookupSpec();

				private final Document letDoc = new Document();

				private final List<Document> pipeline = new ArrayList<>();

				private final List<Document> whereExprs = new ArrayList<>();

				private int varSeq = 0;

				/** $lookup(+optional $unwind) ì´í›„ì— ì ìš©ë  ìŠ¤í…Œì´ì§€ */
				public Builder outerStage(
					Document stage
				) {

					if (stage != null)
						this.outerStages.add( stage );
					return this;

				}

				/** ì—¬ëŸ¬ ì™¸ë¶€ ìŠ¤í…Œì´ì§€ë¥¼ í•œ ë²ˆì— ì¶”ê°€í•©ë‹ˆë‹¤. */
				public Builder outerStages(
					Collection<Document> stages
				) {

					if (stages != null) {
						for (Document s : stages)
							if (s != null)
								this.outerStages.add( s );

					}

					return this;

				}

				public Builder outerMatchExpr(
					Document expr
				) {

					if (expr != null)
						this.outerStages.add( new Document( "$match", new Document( "$expr", expr ) ) );
					return this;

				}

				private Document exprBinary(
					String op, Object left, Object right
				) {

					return new Document( op, List.of( left, right ) );

				}

				private Document exprAnd(
					List<Document> parts
				) {

					if (parts.size() == 1)
						return new Document( "$expr", parts.get( 0 ) );
					return new Document( "$expr", new Document( "$and", parts ) );

				}

				/** NOT {$in: [...] } */
				private Document exprNotIn(
					Object needle, Collection<?> haystack
				) {

					return new Document(
						"$not",
						new Document( "$in", List.of( needle, haystack ) )
					);

				}

				/** field exists in $expr ë°©ì‹: type != "missing" */
				private Document exprExists(
					String rightFieldPath, boolean exists
				) {

					Document type = new Document( "$type", "$" + rightFieldPath );

					if (exists) {
						return exprBinary( "$gt", type, "missing" ); // "$type" > "missing"

					} else {
						return exprBinary( "$eq", type, "missing" );

					}

				}

				/** like/regex: $regexMatch ì‚¬ìš© */
				private Document exprRegexMatch(
					String rightFieldPath, String pattern, Condition.LikeOperator options
				) {

					Document body = new Document( "input", "$" + rightFieldPath )
						.append( "regex", pattern );
					if (options != null)
						body.append( "options", options.name() );
					return new Document( "$regexMatch", body );

				}

				/** all: const âŠ† field (ë‘˜ ë‹¤ ë°°ì—´) â†’ $setIsSubset */
				private Document exprAll(
					Collection<?> constArray, String rightFieldPath
				) {

					return new Document(
						"$setIsSubset",
						List.of( constArray, "$" + rightFieldPath )
					);

				}

				/** between: low <= field <= high */
				private Document exprBetween(
					String rightFieldPath, Object low, Object high
				) {

					Document gte = exprBinary( "$gte", "$" + rightFieldPath, low );
					Document lte = exprBinary( "$lte", "$" + rightFieldPath, high );
					return new Document( "$and", List.of( gte, lte ) );

				}

				// --- ê¸°ë³¸ ë©”íƒ€ ---
				// public Builder from(
				// String from
				// ) {
				//
				// spec.from = from;
				// return this;
				//
				// }

				public Builder as(
					String as
				) {

					spec.as = as;
					return this;

				}

				// --- ê°„ë‹¨ ëª¨ë“œ(local/foreign) ê·¸ëŒ€ë¡œ ì§€ì› ---
				public Builder localField(
					String localField
				) {

					spec.localField = localField;
					return this;

				}

				public Builder foreignField(
					String foreignField
				) {

					spec.foreignField = foreignField;
					return this;

				}

				/** ì™¼ìª½(í˜„ì¬ ì»¬ë ‰ì…˜)ì˜ leftFieldPath ì™€ ì˜¤ë¥¸ìª½ rightFieldPath ì‚¬ì´ì— Condition ì ìš© */
				public Builder bindConditionFields(
					String leftFieldPath, Condition cond, String rightFieldPath
				) {

					String var = nextVar();
					letDoc.put( var, "$" + leftFieldPath ); // $$var = "$leftFieldPath"
					addConditionExpr( cond, "$$" + var, rightFieldPath, null, null, null );
					return this;

				}

				/** ìƒìˆ˜ constValue ì™€ ì˜¤ë¥¸ìª½ rightFieldPath ì‚¬ì´ì— Condition ì ìš© */
				public Builder bindConditionConst(
					Object constValue, Condition cond, String rightFieldPath
				) {

					addConditionExpr( cond, constValue, rightFieldPath, null, null, null );
					return this;

				}
				
				/** 
				 * ì™¼ìª½ í•„ë“œ(String ObjectId hex)ë¥¼ ObjectIdë¡œ ë³€í™˜í•´ì„œ ì˜¤ë¥¸ìª½ í•„ë“œ(ObjectId)ì™€ ë¹„êµí•˜ë„ë¡ ë°”ì¸ë”©
				 * - ì˜ˆ: left.auctionId(String) == right._id(ObjectId)
				 * - $convert ì‚¬ìš©: ë³€í™˜ ì‹¤íŒ¨ ì‹œ nullë¡œ ì²˜ë¦¬ë˜ì–´ ì¿¼ë¦¬ ì—ëŸ¬ ì—†ì´ ë§¤ì¹­ 0ê±´ ì²˜ë¦¬ë¨
				 */
				public Builder bindConditionFieldsLeftToObjectId(
					String leftFieldPath, Condition cond, String rightFieldPath
				) {

					String var = nextVar();

					// $$var = {$convert: {input:"$auctionId", to:"objectId", onError:null, onNull:null}}
					Document toObjectIdExpr = new Document(
						"$convert",
						new Document( "input", "$" + leftFieldPath )
							.append( "to", "objectId" )
							.append( "onError", null )
							.append( "onNull", null )
					);

					letDoc.put( var, toObjectIdExpr );

					// ê¸°ì¡´ addConditionExpr ë¡œì§ ì¬ì‚¬ìš©: $eq: ["$_id", "$$v0"] í˜•íƒœë¡œ ë“¤ì–´ê°
					addConditionExpr( cond, "$$" + var, rightFieldPath, null, null, null );
					return this;

				}
				
				/** between(low, high) ìƒìˆ˜ ë²”ìœ„ */
				public Builder bindConditionBetween(
					Object lowInclusive, Object highInclusive, String rightFieldPath
				) {

					whereExprs.add( exprBetween( rightFieldPath, lowInclusive, highInclusive ) );
					return this;

				}

				/** like/regex ì „ìš© ì˜µì…˜ (ê¸°ë³¸ i-case-insensitive) */
				public Builder bindConditionLike(
					String pattern, String rightFieldPath, Condition.LikeOperator options /* nullable */
				) {

					whereExprs.add( exprRegexMatch( rightFieldPath, pattern, options == null ? Condition.LikeOperator.i : options ) );
					return this;

				}

				/** exists / isNull / isNotNull ì „ìš© */
				public Builder bindConditionExists(
					String rightFieldPath, boolean exists
				) {

					whereExprs.add( exprExists( rightFieldPath, exists ) );
					return this;

				}

				public Builder bindConditionIsNull(
					String rightFieldPath
				) {

					whereExprs.add( exprBinary( "$eq", "$" + rightFieldPath, null ) );
					return this;

				}

				public Builder bindConditionIsNotNull(
					String rightFieldPath
				) {

					whereExprs.add( exprBinary( "$ne", "$" + rightFieldPath, null ) );
					return this;

				}

				/** raw $match stage ì¶”ê°€(ì˜µì…˜) */
				public Builder rawStage(
					Document stage
				) {

					pipeline.add( stage );
					return this;

				}

				/**
				 * $unwind ì„¤ì •
				 *
				 * @param preserveNullAndEmptyArrays
				 *            - false â†’ INNER JOINì²˜ëŸ¼ ë™ì‘ (ë§¤ì¹­ ì—†ìœ¼ë©´ row ì œê±°)
				 *            - true â†’ LEFT OUTER JOINì²˜ëŸ¼ ë™ì‘ (ë§¤ì¹­ ì—†ìœ¼ë©´ null row ìœ ì§€)
				 * 
				 * @return this
				 */
				public Builder unwind(
					boolean preserveNullAndEmptyArrays
				) {

					spec.unwind = true;
					spec.preserveNullAndEmptyArrays = preserveNullAndEmptyArrays;
					return this;

				}

				/** íŒŒì´í”„ë¼ì¸ ë³´ì¡° */
				public Builder limit(
					int n
				) {

					pipeline.add( new Document( "$limit", n ) );
					return this;

				}

				public Builder sort(
					Sort sort
				) {

					if (sort == null || sort.isUnsorted())
						return this;
					Document sortDoc = new Document();
					sort.forEach( o -> sortDoc.append( o.getProperty(), o.isAscending() ? 1 : -1 ) );
					pipeline.add( new Document( "$sort", sortDoc ) );
					return this;

				}

				public LookupSpec build() {

					if (spec.localField == null || spec.foreignField == null) {

						// Condition ê¸°ë°˜ìœ¼ë¡œ ìŒ“ì¸ exprë“¤ì„ í•˜ë‚˜ì˜ $expr $matchë¡œ ë°”ê¿” ì‚½ì…
						if (! whereExprs.isEmpty()) {
							pipeline.add( new Document( "$match", exprAnd( whereExprs ) ) );

						}

						spec.letDoc = letDoc;
						spec.pipelineDocs = pipeline;

					} else {
						spec.letDoc = new Document();
						spec.pipelineDocs = List.of();

					}

					spec.outerStages = this.outerStages;
					return spec;

				}

				private String nextVar() {

					return "v" + (varSeq++);

				}

				/** Condition â†’ $expr ìƒì„±ê¸° (ì™¼ìª½ ê°’ì€ leftVal, ì˜¤ë¥¸ìª½ì€ rightFieldPath) */
				private void addConditionExpr(
					FieldsPair.Condition cond, Object leftValOrConst, // "$$var" ë˜ëŠ” ìƒìˆ˜
					String rightFieldPath, Collection<?> collectionOrNull, Object lowInclusiveOrNull, Object highInclusiveOrNull
				) {

					String rightFieldRef = "$" + rightFieldPath;

					switch (cond) {
						case eq -> whereExprs.add( exprBinary( "$eq", rightFieldRef, leftValOrConst ) );
						case notEq -> whereExprs.add( exprBinary( "$ne", rightFieldRef, leftValOrConst ) );

						case gt -> whereExprs.add( exprBinary( "$gt", rightFieldRef, leftValOrConst ) );
						case gte -> whereExprs.add( exprBinary( "$gte", rightFieldRef, leftValOrConst ) );
						case lt -> whereExprs.add( exprBinary( "$lt", rightFieldRef, leftValOrConst ) );
						case lte -> whereExprs.add( exprBinary( "$lte", rightFieldRef, leftValOrConst ) );

						case in -> {

							if (leftValOrConst instanceof Collection<?> col) {
								whereExprs.add( new Document( "$in", List.of( rightFieldRef, col ) ) );

							} else {
								throw new IllegalArgumentException( "IN requires a collection constant" );

							}

						}
						case notIn -> {

							if (leftValOrConst instanceof Collection<?> col) {
								whereExprs.add( exprNotIn( rightFieldRef, col ) );

							} else {
								throw new IllegalArgumentException( "NOT IN requires a collection constant" );

							}

						}

						case like -> {

							if (! (leftValOrConst instanceof String pat)) { throw new IllegalArgumentException( "LIKE requires string pattern" ); }

							// ê¸°ë³¸ options: "i" (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
							whereExprs.add( exprRegexMatch( rightFieldPath, pat, Condition.LikeOperator.i ) );

						}
						case regex -> {

							if (! (leftValOrConst instanceof String pat)) { throw new IllegalArgumentException( "REGEX requires pattern string" ); }

							// ì˜µì…˜ì€ í•„ìš”í•˜ë©´ bindConditionLike(...)ë¡œ
							whereExprs.add( exprRegexMatch( rightFieldPath, pat, null ) );

						}

						case exists -> {

							if (! (leftValOrConst instanceof Boolean b)) { throw new IllegalArgumentException( "EXISTS requires boolean" ); }

							whereExprs.add( exprExists( rightFieldPath, b ) );

						}
						case isNull -> whereExprs.add( exprBinary( "$eq", rightFieldRef, null ) );
						case isNotNull -> whereExprs.add( exprBinary( "$ne", rightFieldRef, null ) );

						case all -> {

							if (! (leftValOrConst instanceof Collection<?> col)) { throw new IllegalArgumentException( "ALL requires a collection" ); }

							whereExprs.add( exprAll( col, rightFieldPath ) );

						}

						case between -> {

							if (leftValOrConst instanceof Collection<?> values && values.size() == 2) {
								Object[] arr = values.toArray();
								whereExprs.add( exprBetween( rightFieldPath, arr[0], arr[1] ) );

							} else {
								throw new IllegalArgumentException( "BETWEEN requires collection of size 2" );

							}

						}

						// `$lookup` íŒŒì´í”„ë¼ì¸ì˜ $exprì—ì„œ ì§ì ‘ ë‹¤ë£¨ì§€ ì•ŠëŠ”/ì§€ì› ì•ˆ í•˜ëŠ” í•­ëª©
						case near, nearSphere, elemMatch -> throw new UnsupportedOperationException(
							cond + " is not supported in lookup $expr builder; use dedicated geo/array stages."
						);

						default -> throw new IllegalArgumentException( "Unsupported condition: " + cond );

					}

				}

			}

		}



		public interface ExecuteBuilder {

		}


		protected class QueryBuilderAccesser {


			public <KK, V> Grouping<KK, V> group(
				Class<KK> k, Class<V> v
			) {

				return new Grouping<KK, V>( k, v ) {};

			}

			protected String resolveCollectionName(
				Class<?> clazz
			) {

				return reactiveMongoTemplate.getCollectionName( clazz );

			}

			protected String simpleName(
				Class<?> clazz
			) {

				return clazz.getSimpleName();

			}


			protected Mono<Class<E>> getExecuteClassMono() { return executeClassMono; }

			protected String getCollectionName() { return collectionName; }

			protected Mono<Optional<Criteria>> getFieldBuilderCriteria() { return fieldBuilder.buildCriteria(); }

		}

		public class FieldBuilder<S extends E> {

			private Deque<CriteriaGroup> criteriaStack = new ArrayDeque<>();

			/* public FieldBuilder() {
			 * 
			 * // ê¸°ë³¸ì ìœ¼ë¡œ AND ê·¸ë£¹ìœ¼ë¡œ ì‹œì‘
			 * criteriaStack.push( new CriteriaGroup( LogicalOperator.AND ) );
			 * 
			 * } */

			public FieldBuilder() {

				this( LogicalOperator.AND );

			}

			public FieldBuilder(
								LogicalOperator rootOperator
			) {

				LogicalOperator op = (rootOperator == null) ? LogicalOperator.AND : rootOperator;
				// âœ… fields(LogicalOperator.xxx)ë¡œ ì‹œì‘í•  ë•Œ ë£¨íŠ¸ ê·¸ë£¹ì— ë°˜ì˜
				criteriaStack.push( new CriteriaGroup( op ) );

			}

			// í•„ë“œë¥¼ í˜„ì¬ ê·¸ë£¹ì— ì¶”ê°€
			public FieldBuilder<S> fields(
				FieldsPair<?, ?>... fieldsPairs
			) {

				if (fieldsPairs != null && fieldsPairs.length > 0) {

					for (FieldsPair<?, ?> pair : fieldsPairs) {

						if (pair != null) {
							Criteria criteria = createSingleCriteria( pair );

							if (criteria != null) {
								criteriaStack.peek().criteriaList.add( criteria );

							}

						}

					}

				}

				return this;

			}

			public FieldBuilder<S> and() {

				criteriaStack.push( new CriteriaGroup( LogicalOperator.AND ) );
				return this;

			}

			public FieldBuilder<S> or() {

				criteriaStack.push( new CriteriaGroup( LogicalOperator.OR ) );
				return this;

			}

			public FieldBuilder<S> nor() {

				criteriaStack.push( new CriteriaGroup( LogicalOperator.NOR ) );
				return this;

			}

			// í˜„ì¬ ê·¸ë£¹ ì¢…ë£Œ ë° ìƒìœ„ ê·¸ë£¹ì— ì¶”ê°€
			public FieldBuilder<S> endOperator() {

				if (criteriaStack.size() <= 1) { return this; }

				CriteriaGroup finishedGroup = criteriaStack.pop();
				List<Criteria> validCriteria = finishedGroup.criteriaList
					.stream()
					.filter( Objects::nonNull )
					.collect( Collectors.toList() );

				if (! validCriteria.isEmpty()) {
					Criteria groupCriteria;

					switch (finishedGroup.operator) {
						case AND:
							groupCriteria = new Criteria().andOperator( validCriteria );
							break;
						case OR:
							groupCriteria = new Criteria().orOperator( validCriteria );
							break;
						case NOR:
							groupCriteria = new Criteria().norOperator( validCriteria );
							break;
						default:
							throw new IllegalArgumentException( "Unsupported operator: " + finishedGroup.operator );

					}

					// ìƒìœ„ ê·¸ë£¹ì— ì¶”ê°€
					criteriaStack.peek().criteriaList.add( groupCriteria );

				}

				return this;

			}

			public AbstractQueryBuilder<E, T>.QueryBuilderFactory end() {

				while (criteriaStack.size() > 1) {
					endOperator();

				}

				return new QueryBuilderFactory();

			}

			private Mono<Optional<Criteria>> buildCriteria() {

				Mono<Optional<Criteria>> resultMono = Mono.fromCallable( () -> {
					List<Criteria> allCriteria = new ArrayList<>();
					Deque<CriteriaGroup> tempStack = new ArrayDeque<>( criteriaStack );

					while (! tempStack.isEmpty()) {
						CriteriaGroup group = tempStack.pop();

						if (! group.criteriaList.isEmpty()) {
							Criteria combined = null;

							switch (group.operator) {
								case AND:
									combined = new Criteria().andOperator( group.criteriaList );
									break;
								case OR:
									combined = new Criteria().orOperator( group.criteriaList );
									break;
								case NOR:
									combined = new Criteria().norOperator( group.criteriaList );
									break;

							}

							if (combined != null) {
								allCriteria.add( combined );

							}

						}

					}

					if (allCriteria.isEmpty()) { return Optional.empty(); }

					if (allCriteria.size() == 1) { return Optional.of( allCriteria.get( 0 ) ); }

					return Optional.of( new Criteria().andOperator( allCriteria ) );

				} );
				return resultMono;
				// .onErrorMap( e -> new RuntimeException( "Failed to build Criteria: " + e.getMessage(), e ) );


			}

		}

		public class QueryBuilderFactory {

			public FindAllQueryBuilder<E> findAll() {

				return new FindAllQueryBuilder<E>();

			}

			public FindQueryBuilder<E> find() {

				return new FindQueryBuilder<E>();

			}

			public CountQueryBuilder count() {

				return new CountQueryBuilder();

			}


			public DeleteQueryBuilder delete() {

				return new DeleteQueryBuilder();

			}

			public ExistsQueryBuilder exists() {

				return new ExistsQueryBuilder();

			}

			// ì›ìì  update ë¹Œë”
		    public AtomicUpdateQueryBuilder atomicUpdate() {
		        return new AtomicUpdateQueryBuilder();
		    }
		}

		public class FindAllQueryBuilder<S extends E> extends QueryBuilderAccesser {


			private Paging paging;

			private Sort sort = Sort.unsorted();

			private String[] excludes = null;


			public PageBuilder paging() {

				return new PageBuilder();

			}

			public FindAllQueryBuilder<S> paging(
				Integer pageNumber, Integer pageSize
			) {

				return new PageBuilder().and( pageNumber, pageSize );

			}

			public FindAllQueryBuilder<S> sorts(
				Order... sorts
			) {

				this.sort = Sort.by( sorts );
				return this;

			}


			public FindAllQueryBuilder<S> sorts(
				Collection<Order> sorts
			) {

				this.sort = Sort.by( sorts.toArray( Order[]::new ) );
				return this;

			}

			public FindAllQueryBuilder<S> excludes(
				String... excludes
			) {

				this.excludes = excludes;
				return this;

			}


			public FindAllQueryBuilder<S> excludes(
				Collection<String> excludes
			) {

				this.excludes = excludes.toArray( String[]::new );
				return this;

			}

			public class PageBuilder {

				private Integer pageNumber;

				private Integer pageSize;

				public PageBuilder pageNumber(
					int pageNumber
				) {

					this.pageNumber = pageNumber;
					return this;

				}

				public PageBuilder pageSize(
					int pageSize
				) {

					this.pageSize = pageSize;
					return this;

				}

				public FindAllQueryBuilder<S> and(
					Integer pageNumber, Integer pageSize
				) {

					if (pageNumber == null || pageSize == null) { throw new IllegalArgumentException( "Both pageNumber and pageSize must be specified." ); }

					if (pageNumber < 0 || pageSize <= 0) { throw new IllegalArgumentException( "Invalid pageNumber or pageSize." ); }

					paging = new Paging( pageNumber, pageSize );
					return FindAllQueryBuilder.this;

				}

				public FindAllQueryBuilder<S> and() {

					if (pageNumber == null || pageSize == null) { throw new IllegalArgumentException( "Both pageNumber and pageSize must be specified." ); }

					if (pageNumber < 0 || pageSize <= 0) { throw new IllegalArgumentException( "Invalid pageNumber or pageSize." ); }

					paging = new Paging( pageNumber, pageSize );
					return FindAllQueryBuilder.this;

				}

			}

			private class Paging {

				private final int pageNumber;

				private final int pageSize;

				public Paging(
								int pageNumber,
								int pageSize
				) {

					this.pageNumber = pageNumber;
					this.pageSize = pageSize;

				}

			}

			public Mono<PageResult<E>> executeAggregation() {

				// fieldBuilder.buildCriteria()ëŠ” Mono<Optional<Criteria>>ë¥¼ ë°˜í™˜í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
				Mono<Aggregation> aggregationMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					List<AggregationOperation> operations = new ArrayList<>();

					// criteriaOptionalì´ ì¡´ì¬í•˜ë©´ $match ë‹¨ê³„ ì¶”ê°€
					if (criteriaOptional.isPresent()) {
						operations.add( Aggregation.match( criteriaOptional.get() ) );

					}

					// ì •ë ¬ ë‹¨ê³„ ì¶”ê°€ (this.sortê°€ nullì´ ì•„ë‹ˆë¼ê³  ê°€ì •)
					operations
						.add(
							Aggregation
								.sort(
									(this.sort != null && this.sort.isSorted())
										? this.sort
										: Sort.by( Sort.Direction.DESC, "_id" )
								)
						);


					if (paging != null) {
						// operations.add( Aggregation.limit( paging.pageSize ) );
						// operations.add( Aggregation.skip( (long) paging.pageNumber * paging.pageSize ) );

						// "data" facet: ì‹¤ì œ ë°ì´í„°ë¥¼ skip í›„ limit ì ìš©
						AggregationOperation dataFacet = Aggregation.skip( (long) paging.pageNumber * paging.pageSize );
						AggregationOperation dataLimitFacet = Aggregation.limit( paging.pageSize );

						// "totalCount" facet: ì „ì²´ ê°œìˆ˜ë¥¼ ê³„ì‚°
						AggregationOperation countFacet = Aggregation.count().as( "count" );

						FacetOperation facetOperation = Aggregation
							.facet( dataFacet, dataLimitFacet )
							.as( "data" )
							.and( countFacet )
							.as( "totalCount" );
						operations.add( facetOperation );

					}

					// excludesê°€ ìˆì„ ê²½ìš° $project ë‹¨ê³„ë¡œ ì œì™¸í•  í•„ë“œ ì§€ì •
					if (excludes != null && excludes.length != 0) {
						ProjectionOperation projection = Aggregation.project().andExclude( excludes );
						operations.add( projection );

					}

					Aggregation aggregation = applyAggOptions( Aggregation.newAggregation( operations ) );

					return aggregation;

				} );
				Mono<PageResult<E>> result = Mono
					.zip( executeClassMono, aggregationMono )
					.flatMap( tuple -> {
						Class<E> entityClass = tuple.getT1();
						Aggregation aggregation = tuple.getT2();

						// collectionNameì´ ì§€ì •ë˜ì–´ ìˆìœ¼ë©´ í•´ë‹¹ ì»¬ë ‰ì…˜ì—ì„œ Aggregation ì‹¤í–‰
						Flux<Document> resultDocument;

						if (collectionName != null && ! collectionName.isBlank()) {
							resultDocument = reactiveMongoTemplate
								.aggregate( aggregation, collectionName, Document.class );

						} else {
							resultDocument = reactiveMongoTemplate
								.aggregate( aggregation, entityClass, Document.class );

						}

						return resultDocument
							.single()
							.map( doc -> {
								// "data" ë°°ì—´ ì¶”ì¶œ í›„, Entityë¡œ ë§¤í•‘
								@SuppressWarnings("unchecked")
								List<Document> dataDocs = (List<Document>) doc.get( "data" );
								List<E> entities = dataDocs
									.stream()
									.map( document -> reactiveMongoTemplate.getConverter().read( entityClass, document ) )
									.collect( Collectors.toList() );

								// "totalCount" ë°°ì—´ì—ì„œ ì „ì²´ ê°œìˆ˜ ì¶”ì¶œ
								@SuppressWarnings("unchecked")
								List<Document> countDocs = (List<Document>) doc.get( "totalCount" );
								Number countNumber = countDocs.isEmpty()
									? 0
									: countDocs.get( 0 ).get( "count", Number.class );
								long totalCount = countNumber == null ? 0 : countNumber.longValue();
								return new PageResult<>( entities, totalCount );

							} );

					} );

				return result;
				// .onErrorMap( e -> new RuntimeException( "Failed to find with: " + e.getMessage(), e ) );

			}

			public <R2> Mono<PageResult<ResultTuple<S, List<R2>>>> executeLookupAndCount(
				AbstractQueryBuilder<R2, ?>.FindAllQueryBuilder<R2> rightBuilder, LookupSpec spec
			) {

				Mono<Class<E>> leftClassMono = executeClassMono;
				Mono<Class<R2>> rightClassMono = rightBuilder.getExecuteClassMono();
				// rightBuilder
				return Mono
					.zip(
						fieldBuilder.buildCriteria(), // ì™¼ìª½ match
						rightBuilder.getFieldBuilderCriteria(),
						leftClassMono,
						rightClassMono
					)
					.flatMap( tuple -> {
						Optional<Criteria> leftCriteriaOpt = tuple.getT1();
						Optional<Criteria> rightCriteriaOpt = tuple.getT2();
						Class<E> leftClass = tuple.getT3();
						Class<R2> rightClass = tuple.getT4();

						String leftCollection = (collectionName != null && ! collectionName.isBlank())
							? collectionName
							: resolveCollectionName( leftClass );

						String rightCollection = (rightBuilder.getCollectionName() != null && ! rightBuilder.getCollectionName().isBlank())
							? rightBuilder.getCollectionName()
							: rightBuilder.resolveCollectionName( rightClass );

						String leftKey = simpleName( leftClass );
						String rightAs = (spec.as != null && ! spec.as.isBlank()) ? spec.as : simpleName( rightClass );
						String rightKey = simpleName( rightClass );

						// ===== ê³µí†µ ìŠ¤í…Œì´ì§€ ë¹Œë“œ =====
						List<AggregationOperation> common = new ArrayList<>();
						leftCriteriaOpt.ifPresent( c -> common.add( Aggregation.match( c ) ) );

						// $lookup
						Document lookupBody = new Document( "from", rightCollection ).append( "as", rightAs );

						// spec.pipelineDocs ë¶„í•´: $limit(ë“¤)ì€ ëìœ¼ë¡œ ë³´ë‚´ê¸° ìœ„í•´ ë”°ë¡œ ëª¨ì•„ë‘ 
						List<Document> userStages = Optional.ofNullable( spec.pipelineDocs ).orElseGet( List::of );
						List<Document> nonLimitStages = new ArrayList<>();
						List<Document> limitStages = new ArrayList<>();

						for (Document st : userStages) {
							if (st.containsKey( "$limit" ))
								limitStages.add( st );
							else
								nonLimitStages.add( st );

						}

						boolean needPipeline = (spec.localField == null || spec.foreignField == null) // ì›ë˜ pipeline ëª¨ë“œ
							|| rightCriteriaOpt.isPresent() // ì˜¤ë¥¸ìª½ ì¶”ê°€ í•„í„° ìˆìŒ
							|| ! nonLimitStages.isEmpty() || ! limitStages.isEmpty(); // ì‚¬ìš©ìê°€ ë„£ì€ stage ìˆìŒ

						if (! needPipeline) {
							// ë‹¨ìˆœ ëª¨ë“œ: í‰ë¬¸ í•„ë“œëª… (ì ‘ë‘ $ ë„£ì§€ ì•ŠìŒ)
							lookupBody
								.append( "localField", spec.localField )
								.append( "foreignField", spec.foreignField );

						} else {
							List<Document> pipe = new ArrayList<>();

							// 1) ì˜¤ë¥¸ìª½ ì¼ë°˜ í•„í„°ë¥¼ ë¨¼ì € (ì¸ë±ìŠ¤ íƒ€ê²Œ)
							rightCriteriaOpt.ifPresent( rc -> pipe.add( new Document( "$match", rc.getCriteriaObject() ) ) );

							// 2) local/foreign ìˆë‹¤ë©´ $expr ì¡°ì¸ì‹ ì¶”ê°€ (let í•„ìš”)
							if (spec.localField != null && spec.foreignField != null) {
								String lfVar = "vlf"; // ë°˜ë“œì‹œ ì˜ë¬¸ìë¡œ ì‹œì‘
								lookupBody.append( "let", new Document( lfVar, "$" + spec.localField ) );
								pipe
									.add(
										new Document(
											"$match",
											new Document(
												"$expr",
												new Document( "$eq", Arrays.asList( "$" + spec.foreignField, "$$" + lfVar ) )
											)
										)
									);

							} else {
								// let ê·¸ëŒ€ë¡œ ìœ ì§€ (ì—†ìœ¼ë©´ ë¹ˆ Document)
								lookupBody.append( "let", Optional.ofNullable( spec.letDoc ).orElseGet( Document::new ) );

							}

							boolean onlyProjects = ! nonLimitStages.isEmpty() && nonLimitStages.stream().allMatch( st -> st.containsKey( "$project" ) );

							if (onlyProjects) {
								// EXISTS ìµœì í™”: limit â†’ project (í›„ë³´ë¥¼ 1ê±´ìœ¼ë¡œ ì¤„ì¸ ë‹¤ìŒ project)
								pipe.addAll( limitStages );
								pipe.addAll( nonLimitStages );

							} else {
								// ì¼ë°˜ ì¼€ì´ìŠ¤: ê¸°ì¡´ ìˆœì„œ ìœ ì§€
								pipe.addAll( nonLimitStages );
								pipe.addAll( limitStages );

							}

							lookupBody.append( "pipeline", pipe );

						}

						AggregationOperation lookupOp = (ctx) -> new Document( "$lookup", lookupBody );
						common.add( lookupOp );

						if (spec.unwind) {
							Document unwind = new Document(
								"$unwind",
								new Document( "path", "$" + rightAs )
									.append( "preserveNullAndEmptyArrays", spec.preserveNullAndEmptyArrays )
							);
							common.add( ctx -> unwind );

						}

						if (spec.getOuterStages() != null && ! spec.getOuterStages().isEmpty()) {

							for (Document st : spec.getOuterStages()) {
								common.add( ctx -> st );

							}

						}

						// ===== data ì„œë¸ŒíŒŒì´í”„ë¼ì¸ =====
						List<AggregationOperation> dataOps = new ArrayList<>( common );
						dataOps
							.add(
								Aggregation
									.sort(
										(this.sort != null && this.sort.isSorted()) ? this.sort : Sort.by( Sort.Direction.DESC, "_id" )
									)
							);

						if (this.paging != null) {
							dataOps.add( Aggregation.skip( (long) this.paging.pageNumber * this.paging.pageSize ) );
							dataOps.add( Aggregation.limit( this.paging.pageSize ) );

						}

						// í”„ë¡œì íŠ¸: { LeftName: $$ROOT, RightName: $<rightAs> }
						Document project = new Document(
							"$project",
							new Document()
								.append( leftKey, "$$ROOT" )
								.append( rightKey, "$" + rightAs )
						);
						dataOps.add( ctx -> project );

						// ===== count ì„œë¸ŒíŒŒì´í”„ë¼ì¸ (isCounitng == trueì¼ ë•Œë§Œ) =====
						List<AggregationOperation> countOps = new ArrayList<>( common );
						// ì •ë ¬/í˜ì´ì§•/í”„ë¡œì ì…˜ ì—†ì´, ë™ì¼ ì¡°ê±´ ê¸°ì¤€ìœ¼ë¡œ ê°œìˆ˜ë§Œ ì§‘ê³„
						countOps.add( Aggregation.count().as( "totalCount" ) );


						// ===== $facet êµ¬ì„± =====
						FacetOperation facetOp = Aggregation
							.facet( dataOps.toArray( new AggregationOperation[0] ) )
							.as( "data" )
							.and( countOps.toArray( new AggregationOperation[0] ) )
							.as( "count" );

						Aggregation agg = applyAggOptions(
							Aggregation
								.newAggregation( facetOp )
						);


						Mono<Document> facetDocMono = ((collectionName != null && ! collectionName.isBlank())
							? reactiveMongoTemplate.aggregate( agg, leftCollection, Document.class )
							: reactiveMongoTemplate.aggregate( agg, leftClass, Document.class )).next(); // $facet ê²°ê³¼ëŠ” 1ë¬¸ì„œ

						return facetDocMono.flatMap( facetDoc -> {
							@SuppressWarnings("unchecked")
							List<Document> dataArr = (List<Document>) facetDoc.getOrDefault( "data", List.of() );

							// data ë§¤í•‘
							List<ResultTuple<S, List<R2>>> data = dataArr.stream().map( d -> {
								@SuppressWarnings("unchecked")
								S leftVal = (S) reactiveMongoTemplate.getConverter().read( leftClass, (Document) d.get( leftKey ) );

								Object rawRight = d.get( rightKey );
								List<R2> rightVal;

								if (rawRight instanceof List<?> rawList) {
									@SuppressWarnings("unchecked")
									List<Document> rightDocs = (List<Document>) rawList;
									rightVal = rightDocs
										.stream()
										.map( x -> reactiveMongoTemplate.getConverter().read( rightClass, x ) )
										.collect( Collectors.toList() );

								} else if (rawRight instanceof Document rd) {
									// unwind(true) ì¼€ì´ìŠ¤: ë‹¨ê±´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë˜í•‘
									rightVal = List.of( reactiveMongoTemplate.getConverter().read( rightClass, rd ) );

								} else {
									rightVal = List.of();

								}

								return new ResultTuple<>( leftKey, leftVal, rightKey, rightVal );

							} ).collect( Collectors.toList() );

							Long totalCount = 0L;

							@SuppressWarnings("unchecked")
							List<Document> countArr = (List<Document>) facetDoc.getOrDefault( "count", List.of() );

							if (! countArr.isEmpty()) {
								Object n = countArr.get( 0 ).get( "totalCount" );
								if (n instanceof Number)
									totalCount = ((Number) n).longValue();
								else if (n != null)
									totalCount = Long.parseLong( n.toString() );
								else
									totalCount = 0L;

							}

							return Mono.just( new PageResult<>( data, totalCount ) );

						} );

					} );

			}

			public <R2  > Flux<ResultTuple<S, List<R2>>> executeLookup(
				AbstractQueryBuilder<R2, ?>.FindAllQueryBuilder<R2> rightBuilder, LookupSpec spec
			) {

				// ì™¼ìª½/ì˜¤ë¥¸ìª½ í´ë˜ìŠ¤, ì»¬ë ‰ì…˜ëª… ê²°ì •
				Mono<Class<E>> leftClassMono = executeClassMono;
				Mono<Class<R2>> rightClassMono = rightBuilder.getExecuteClassMono();


				Mono<Aggregation> aggMono = Mono
					.zip(
						fieldBuilder.buildCriteria(), // ì™¼ìª½ match
						rightBuilder.getFieldBuilderCriteria(),
						leftClassMono,
						rightClassMono
					)
					.map( tuple -> {
						Optional<Criteria> leftCriteriaOpt = tuple.getT1();
						Optional<Criteria> rightCriteriaOpt = tuple.getT2();
						Class<E> leftClass = tuple.getT3();
						Class<R2> rightClass = tuple.getT4();

						// String leftCollection = (collectionName != null && ! collectionName.isBlank())
						// ? collectionName
						// : resolveCollectionName( leftClass );

						String rightCollection = (rightBuilder.getCollectionName() != null && ! rightBuilder.getCollectionName().isBlank())
							? rightBuilder.getCollectionName()
							: rightBuilder.resolveCollectionName( rightClass );

						String leftKey = simpleName( leftClass );
						String rightAs = (spec.as != null && ! spec.as.isBlank()) ? spec.as : simpleName( rightClass );
						String rightKey = simpleName( rightClass );

						List<AggregationOperation> ops = new ArrayList<>();
						leftCriteriaOpt.ifPresent( c -> ops.add( Aggregation.match( c ) ) );

						// $lookup êµ¬ì„±
						Document lookupBody = new Document( "from", rightCollection ).append( "as", rightAs );

						// spec.pipelineDocs ë¶„í•´: $limit(ë“¤)ì€ ëìœ¼ë¡œ ë³´ë‚´ê¸° ìœ„í•´ ë”°ë¡œ ëª¨ì•„ë‘ 
						List<Document> userStages = Optional.ofNullable( spec.pipelineDocs ).orElseGet( List::of );
						List<Document> nonLimitStages = new ArrayList<>();
						List<Document> limitStages = new ArrayList<>();

						for (Document st : userStages) {
							if (st.containsKey( "$limit" ))
								limitStages.add( st );
							else
								nonLimitStages.add( st );

						}

						boolean needPipeline = (spec.localField == null || spec.foreignField == null) // ì›ë˜ pipeline ëª¨ë“œ
							|| rightCriteriaOpt.isPresent() // ì˜¤ë¥¸ìª½ ì¶”ê°€ í•„í„° ìˆìŒ
							|| ! nonLimitStages.isEmpty() || ! limitStages.isEmpty(); // ì‚¬ìš©ìê°€ ë„£ì€ stage ìˆìŒ

						if (! needPipeline) {
							// ë‹¨ìˆœ ëª¨ë“œ: í‰ë¬¸ í•„ë“œëª… (ì ‘ë‘ $ ë„£ì§€ ì•ŠìŒ)
							lookupBody
								.append( "localField", spec.localField )
								.append( "foreignField", spec.foreignField );

						} else {
							List<Document> pipe = new ArrayList<>();

							// 1) ì˜¤ë¥¸ìª½ ì¼ë°˜ í•„í„°ë¥¼ ë¨¼ì € (ì¸ë±ìŠ¤ íƒ€ê²Œ)
							rightCriteriaOpt.ifPresent( rc -> pipe.add( new Document( "$match", rc.getCriteriaObject() ) ) );

							// 2) local/foreign ìˆë‹¤ë©´ $expr ì¡°ì¸ì‹ ì¶”ê°€ (let í•„ìš”)
							if (spec.localField != null && spec.foreignField != null) {
								String lfVar = "vlf"; // ë°˜ë“œì‹œ ì˜ë¬¸ìë¡œ ì‹œì‘
								lookupBody.append( "let", new Document( lfVar, "$" + spec.localField ) );
								pipe
									.add(
										new Document(
											"$match",
											new Document(
												"$expr",
												new Document( "$eq", Arrays.asList( "$" + spec.foreignField, "$$" + lfVar ) )
											)
										)
									);

							} else {
								// let ê·¸ëŒ€ë¡œ ìœ ì§€ (ì—†ìœ¼ë©´ ë¹ˆ Document)
								lookupBody.append( "let", Optional.ofNullable( spec.letDoc ).orElseGet( Document::new ) );

							}

							boolean onlyProjects = ! nonLimitStages.isEmpty() && nonLimitStages.stream().allMatch( st -> st.containsKey( "$project" ) );

							if (onlyProjects) {
								// EXISTS ìµœì í™”: limit â†’ project (í›„ë³´ë¥¼ 1ê±´ìœ¼ë¡œ ì¤„ì¸ ë‹¤ìŒ project)
								pipe.addAll( limitStages );
								pipe.addAll( nonLimitStages );

							} else {
								// ì¼ë°˜ ì¼€ì´ìŠ¤: ê¸°ì¡´ ìˆœì„œ ìœ ì§€
								pipe.addAll( nonLimitStages );
								pipe.addAll( limitStages );

							}

							lookupBody.append( "pipeline", pipe );

						}

						AggregationOperation lookupOp = (ctx) -> new Document( "$lookup", lookupBody );
						ops.add( lookupOp );

						if (spec.unwind) {
							Document unwind = new Document(
								"$unwind",
								new Document( "path", "$" + rightAs )
									.append( "preserveNullAndEmptyArrays", spec.preserveNullAndEmptyArrays )
							);
							ops.add( ctx -> unwind );

						}

						if (spec.getOuterStages() != null && ! spec.getOuterStages().isEmpty()) {

							for (Document st : spec.getOuterStages()) {
								ops.add( ctx -> st );

							}

						}

						// ì •ë ¬/í˜ì´ì§•(ì™¼ìª½ ê¸°ì¤€) ìœ ì§€
						ops.add( Aggregation.sort( (this.sort != null && this.sort.isSorted()) ? this.sort : Sort.by( Sort.Direction.DESC, "_id" ) ) );

						if (this.paging != null) {
							ops.add( Aggregation.skip( (long) this.paging.pageNumber * this.paging.pageSize ) );
							ops.add( Aggregation.limit( this.paging.pageSize ) );

						}

						// ê²°ê³¼ ëª¨ì–‘: { LeftName: $$ROOT, RightName: $<rightAs> }
						Document project = new Document(
							"$project",
							new Document()
								.append( leftKey, "$$ROOT" )
								.append( rightKey, "$" + rightAs )
						);
						ops.add( ctx -> project );

						Aggregation agg = applyAggOptions( Aggregation.newAggregation( ops ) );

						return agg;

					} );

				return Mono
					.zip( leftClassMono, rightClassMono, aggMono )
					.flatMapMany( tuple -> {
						Class<E> leftClass = tuple.getT1();
						Class<R2> rightClass = tuple.getT2();
						Aggregation agg = tuple.getT3();

						Flux<Document> docs = (collectionName != null && ! collectionName.isBlank())
							? reactiveMongoTemplate.aggregate( agg, collectionName, Document.class )
							: reactiveMongoTemplate.aggregate( agg, leftClass, Document.class );

						String leftKey = simpleName( leftClass );
						String rightKey = simpleName( rightClass );

						return docs.map( d -> {
							@SuppressWarnings("unchecked")
							S leftVal = (S) reactiveMongoTemplate.getConverter().read( leftClass, (Document) d.get( leftKey ) );

							@SuppressWarnings("unchecked")
							List<Document> rightArr = (List<Document>) d.get( rightKey );

							List<R2> rightVal = (rightArr == null) ? List.of()
								: rightArr
									.stream()
									.map( x -> reactiveMongoTemplate.getConverter().read( rightClass, x ) )
									.collect( Collectors.toList() );

							return new ResultTuple<>( leftKey, leftVal, rightKey, rightVal );

						} );

					} );

			}


			public Flux<E> execute() {

				var queryMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					Query query = new Query();

					if (criteriaOptional.isPresent()) {
						query.addCriteria( criteriaOptional.get() );

					}

					if (paging != null) {
						query.skip( (long) paging.pageNumber * paging.pageSize ).limit( paging.pageSize );

					}

					query.with( this.sort );

					if (excludes != null && excludes.length != 0) {
						query.fields().exclude( excludes );
						// query.fields().slice( collectionName, 0 );

					}

					applyQueryOptions( query );

					if (excludes != null && excludes.length > 0) {
						var fields = query.fields();
						Arrays
							.stream( excludes )
							.filter( s -> s != null && ! s.isBlank() )
							.forEach( fields::exclude );

					}

					return query;

				} );
				Flux<E> result = Mono
					.zip( executeClassMono, queryMono )
					.flatMapMany( tuple -> {
						var entityClass = tuple.getT1();
						var query = tuple.getT2();
						Flux<? extends E> queryResult = collectionName != null && ! collectionName.isBlank() ? reactiveMongoTemplate.find( query, entityClass, collectionName )
							: reactiveMongoTemplate.find( query, entityClass );
						return queryResult;

					} );

				return result;
				// .onErrorMap( e -> new RuntimeException( "Failed to find with : " + e.getMessage(), e ) );

			}

		}

		public class FindQueryBuilder<S extends E> extends QueryBuilderAccesser {

			private Sort sort = Sort.unsorted();

			private String[] excludes = null;


			public FindQueryBuilder<S> sorts(
				Order... sorts
			) {

				this.sort = Sort.by( sorts );
				return this;

			}

			public FindQueryBuilder<S> sorts(
				Collection<Order> sorts
			) {

				this.sort = Sort.by( sorts.toArray( Order[]::new ) );
				return this;

			}

			public FindQueryBuilder<S> excludes(
				String... excludes
			) {

				this.excludes = excludes;
				return this;

			}


			public FindQueryBuilder<S> excludes(
				Collection<String> excludes
			) {

				this.excludes = excludes.toArray( String[]::new );
				return this;

			}

			public <R2  > Mono<ResultTuple<S, R2>> executeLookup(
				AbstractQueryBuilder<R2, ?>.FindQueryBuilder<R2> rightBuilder, LookupSpec spec
			) {

				// ë‚´ë¶€ì ìœ¼ë¡œ FindAllê³¼ ê±°ì˜ ë™ì¼í•˜ë˜, limit(1) ë³´ì¥
				Mono<Class<E>> leftClassMono = executeClassMono;
				Mono<Class<R2>> rightClassMono = rightBuilder.getExecuteClassMono();

				Mono<Aggregation> aggMono = Mono
					.zip(
						fieldBuilder.buildCriteria(),
						rightBuilder.getFieldBuilderCriteria(),
						leftClassMono,
						rightClassMono
					)
					.map( tuple -> {
						Optional<Criteria> leftCriteriaOpt = tuple.getT1();
						Optional<Criteria> rightCriteriaOpt = tuple.getT2();
						Class<E> leftClass = tuple.getT3();
						Class<R2> rightClass = tuple.getT4();

						// String leftCollection = (collectionName != null && ! collectionName.isBlank())
						// ? collectionName
						// : resolveCollectionName( leftClass );

						String rightCollection = (rightBuilder.getCollectionName() != null && ! rightBuilder.getCollectionName().isBlank())
							? rightBuilder.getCollectionName()
							: rightBuilder.resolveCollectionName( rightClass );

						String leftKey = simpleName( leftClass );
						String rightAs = (spec.as != null && ! spec.as.isBlank()) ? spec.as : simpleName( rightClass );
						String rightKey = simpleName( rightClass );

						List<AggregationOperation> ops = new ArrayList<>();
						leftCriteriaOpt.ifPresent( c -> ops.add( Aggregation.match( c ) ) );

						Document lookupBody = new Document( "from", rightCollection ).append( "as", rightAs );

						// spec.pipelineDocs ë¶„í•´: $limit(ë“¤)ì€ ëìœ¼ë¡œ ë³´ë‚´ê¸° ìœ„í•´ ë”°ë¡œ ëª¨ì•„ë‘ 
						List<Document> userStages = Optional.ofNullable( spec.pipelineDocs ).orElseGet( List::of );
						List<Document> nonLimitStages = new ArrayList<>();
						List<Document> limitStages = new ArrayList<>();

						for (Document st : userStages) {
							if (st.containsKey( "$limit" ))
								limitStages.add( st );
							else
								nonLimitStages.add( st );

						}

						boolean needPipeline = (spec.localField == null || spec.foreignField == null) // ì›ë˜ pipeline ëª¨ë“œ
							|| rightCriteriaOpt.isPresent() // ì˜¤ë¥¸ìª½ ì¶”ê°€ í•„í„° ìˆìŒ
							|| ! nonLimitStages.isEmpty() || ! limitStages.isEmpty(); // ì‚¬ìš©ìê°€ ë„£ì€ stage ìˆìŒ

						if (! needPipeline) {
							// ë‹¨ìˆœ ëª¨ë“œ: í‰ë¬¸ í•„ë“œëª… (ì ‘ë‘ $ ë„£ì§€ ì•ŠìŒ)
							lookupBody
								.append( "localField", spec.localField )
								.append( "foreignField", spec.foreignField );

						} else {
							List<Document> pipe = new ArrayList<>();

							// 1) ì˜¤ë¥¸ìª½ ì¼ë°˜ í•„í„°ë¥¼ ë¨¼ì € (ì¸ë±ìŠ¤ íƒ€ê²Œ)
							rightCriteriaOpt.ifPresent( rc -> pipe.add( new Document( "$match", rc.getCriteriaObject() ) ) );

							// 2) local/foreign ìˆë‹¤ë©´ $expr ì¡°ì¸ì‹ ì¶”ê°€ (let í•„ìš”)
							if (spec.localField != null && spec.foreignField != null) {
								String lfVar = "vlf"; // ë°˜ë“œì‹œ ì˜ë¬¸ìë¡œ ì‹œì‘
								lookupBody.append( "let", new Document( lfVar, "$" + spec.localField ) );
								pipe
									.add(
										new Document(
											"$match",
											new Document(
												"$expr",
												new Document( "$eq", Arrays.asList( "$" + spec.foreignField, "$$" + lfVar ) )
											)
										)
									);

							} else {
								// let ê·¸ëŒ€ë¡œ ìœ ì§€ (ì—†ìœ¼ë©´ ë¹ˆ Document)
								lookupBody.append( "let", Optional.ofNullable( spec.letDoc ).orElseGet( Document::new ) );

							}

							boolean onlyProjects = ! nonLimitStages.isEmpty() && nonLimitStages.stream().allMatch( st -> st.containsKey( "$project" ) );

							if (onlyProjects) {
								// EXISTS ìµœì í™”: limit â†’ project (í›„ë³´ë¥¼ 1ê±´ìœ¼ë¡œ ì¤„ì¸ ë‹¤ìŒ project)
								pipe.addAll( limitStages );
								pipe.addAll( nonLimitStages );

							} else {
								// ì¼ë°˜ ì¼€ì´ìŠ¤: ê¸°ì¡´ ìˆœì„œ ìœ ì§€
								pipe.addAll( nonLimitStages );
								pipe.addAll( limitStages );

							}

							lookupBody.append( "pipeline", pipe );

						}

						ops.add( ctx -> new Document( "$lookup", lookupBody ) );

						if (spec.unwind) {
							ops
								.add(
									ctx -> new Document(
										"$unwind",
										new Document( "path", "$" + rightAs )
											.append( "preserveNullAndEmptyArrays", spec.preserveNullAndEmptyArrays )
									)
								);

						}

						if (spec.getOuterStages() != null && ! spec.getOuterStages().isEmpty()) {

							for (Document st : spec.getOuterStages()) {
								ops.add( ctx -> st );

							}

						}

						// sort + limit(1)
						ops.add( Aggregation.sort( (this.sort != null && this.sort.isSorted()) ? this.sort : Sort.by( Sort.Direction.DESC, "_id" ) ) );
						ops.add( Aggregation.limit( 1 ) );

						Document project = new Document(
							"$project",
							new Document()
								.append( leftKey, "$$ROOT" )
								.append( rightKey, "$" + rightAs )
						);
						ops.add( ctx -> project );

						Aggregation agg = applyAggOptions( Aggregation.newAggregation( ops ) );


						// agg.withOptions( Aggregation.newAggregationOptions().allowDiskUse( false ).build() );
						return agg;

					} );

				return Mono
					.zip( leftClassMono, rightClassMono, aggMono )
					.flatMap( tuple -> {
						Class<E> leftClass = tuple.getT1();
						Class<R2> rightClass = tuple.getT2();
						Aggregation agg = tuple.getT3();

						Flux<Document> docs = (collectionName != null && ! collectionName.isBlank())
							? reactiveMongoTemplate.aggregate( agg, collectionName, Document.class )
							: reactiveMongoTemplate.aggregate( agg, leftClass, Document.class );

						String leftKey = simpleName( leftClass );
						String rightKey = simpleName( rightClass );

						return docs.next().map( d -> {
							@SuppressWarnings("unchecked")
							S leftVal = (S) reactiveMongoTemplate.getConverter().read( leftClass, (Document) d.get( leftKey ) );

							Object raw = d.get( rightKey );
							R2 rightVal = null;

							if (raw instanceof Document rd) {
								rightVal = reactiveMongoTemplate.getConverter().read( rightClass, rd );

							} else if (raw instanceof List<?> rl && ! rl.isEmpty() && rl.get( 0 ) instanceof Document r0) {
								rightVal = reactiveMongoTemplate.getConverter().read( rightClass, r0 ); // ì²« ì›ì†Œ

							}

							return new ResultTuple<>( leftKey, leftVal, rightKey, rightVal );

						} );

					} );

			}

			public Mono<E> execute() {

				var queryMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					Query query = new Query();

					if (criteriaOptional.isPresent()) {
						query.addCriteria( criteriaOptional.get() );

					}

					query.with( this.sort );


					applyQueryOptions( query );


					if (excludes != null && excludes.length > 0) {
						var fields = query.fields();
						Arrays
							.stream( excludes )
							.filter( s -> s != null && ! s.isBlank() )
							.forEach( fields::exclude );

					}

					return query;

				} );
				Mono<E> result = Mono
					.zip( executeClassMono, queryMono )
					.flatMap( tuple -> {
						var entityClass = tuple.getT1();
						var query = tuple.getT2();
						if (collectionName != null && ! collectionName.isBlank())
							return reactiveMongoTemplate.findOne( query, entityClass, collectionName );
						else
							return reactiveMongoTemplate.findOne( query, entityClass );


					} );
				return result;// .onErrorMap( e -> new RuntimeException( "Failed to find by fields: " + e.getMessage(), e ) );

			}

			public Mono<E> executeFirst() {

				var queryMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					Query query = new Query();

					if (criteriaOptional.isPresent()) {
						query.addCriteria( criteriaOptional.get() );

					}

					query.limit( 1 );
					query.with( sort );

					applyQueryOptions( query );

					if (excludes != null && excludes.length > 0) {
						var fields = query.fields();
						Arrays
							.stream( excludes )
							.filter( s -> s != null && ! s.isBlank() )
							.forEach( fields::exclude );

					}

					return query;

				} );

				Mono<E> result = Mono
					.zip( executeClassMono, queryMono )
					.flatMap( tuple -> {
						var entityClass = tuple.getT1();
						var query = tuple.getT2();
						if (collectionName != null && ! collectionName.isBlank())
							return reactiveMongoTemplate.findOne( query, entityClass, collectionName );
						else
							return reactiveMongoTemplate.findOne( query, entityClass );


					} );
				return result
					.doOnError( e -> {
						e.printStackTrace();

					} );

			}

			public Mono<E> executeAggregation() {

				Mono<Aggregation> aggregationMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					List<AggregationOperation> ops = new ArrayList<>();

					// where ì ˆ ($match)
					criteriaOptional.ifPresent( c -> ops.add( Aggregation.match( c ) ) );

					// ì •ë ¬
					ops
						.add(
							Aggregation
								.sort(
									(this.sort != null && this.sort.isSorted())
										? this.sort
										: Sort.by( Sort.Direction.DESC, "_id" )
								)
						);

					// ë‹¨ê±´ë§Œ
					ops.add( Aggregation.limit( 1 ) );

					// í”„ë¡œì íŠ¸ (exclude)
					if (excludes != null && excludes.length > 0) {
						ops.add( Aggregation.project().andExclude( excludes ) );

					}

					Aggregation agg = applyAggOptions( Aggregation.newAggregation( ops ) );

					return agg;

				} );

				return Mono
					.zip( executeClassMono, aggregationMono )
					.flatMap( tuple -> {
						Class<E> entityClass = tuple.getT1();
						Aggregation aggregation = tuple.getT2();

						Flux<Document> docs = (collectionName != null && ! collectionName.isBlank())
							? reactiveMongoTemplate.aggregate( aggregation, collectionName, Document.class )
							: reactiveMongoTemplate.aggregate( aggregation, entityClass, Document.class );

						// ì²« ë¬¸ì„œë¥¼ ì—”í‹°í‹°ë¡œ ë§¤í•‘ (ì—†ìœ¼ë©´ empty Mono)
						return docs.next().map( doc -> reactiveMongoTemplate.getConverter().read( entityClass, doc ) );

					} );

			}

		}

		public class CountQueryBuilder extends QueryBuilderAccesser {

			public <R2  > Mono<ResultTuple<Long, Long>> executeLookup(
				AbstractQueryBuilder<R2, ?>.FindAllQueryBuilder<R2> rightBuilder, LookupSpec spec
			) {

				Mono<Class<E>> leftClassMono = executeClassMono;
				Mono<Class<R2>> rightClassMono = rightBuilder.getExecuteClassMono();

				Mono<Aggregation> aggMono = Mono
					.zip(
						fieldBuilder.buildCriteria(),
						rightBuilder.getFieldBuilderCriteria(),
						leftClassMono,
						rightClassMono
					)
					.map( tp -> {
						Optional<Criteria> leftMatch = tp.getT1();
						Optional<Criteria> rightMatch = tp.getT2();
						Class<E> leftClass = tp.getT3();
						Class<R2> rightClass = tp.getT4();

						String rightColl = (rightBuilder.getCollectionName() != null && ! rightBuilder.getCollectionName().isBlank())
							? rightBuilder.getCollectionName()
							: rightBuilder.resolveCollectionName( rightClass );

						// String leftKey = simpleName( leftClass );
						String rightAs = (spec.as != null && ! spec.as.isBlank()) ? spec.as : simpleName( rightClass );
						// String rightKey = simpleName( rightClass ); // ì´ë¦„ë§Œ ì“¸ê±°ë¼ í‚¤ë¡œë„ ì‚¬ìš©

						List<AggregationOperation> ops = new ArrayList<>();
						leftMatch.ifPresent( c -> ops.add( Aggregation.match( c ) ) );

						// $lookup
						Document lk = new Document( "from", rightColl ).append( "as", rightAs );
						// spec.pipelineDocs ë¶„í•´: $limit(ë“¤)ì€ ëìœ¼ë¡œ ë³´ë‚´ê¸° ìœ„í•´ ë”°ë¡œ ëª¨ì•„ë‘ 
						List<Document> userStages = Optional.ofNullable( spec.pipelineDocs ).orElseGet( List::of );
						List<Document> nonLimitStages = new ArrayList<>();
						List<Document> limitStages = new ArrayList<>();

						for (Document st : userStages) {
							if (st.containsKey( "$limit" ))
								limitStages.add( st );
							else
								nonLimitStages.add( st );

						}

						boolean needPipeline = (spec.localField == null || spec.foreignField == null) // ì›ë˜ pipeline ëª¨ë“œ
							|| rightMatch.isPresent() // ì˜¤ë¥¸ìª½ ì¶”ê°€ í•„í„° ìˆìŒ
							|| ! nonLimitStages.isEmpty() || ! limitStages.isEmpty(); // ì‚¬ìš©ìê°€ ë„£ì€ stage ìˆìŒ

						if (! needPipeline) {
							// ë‹¨ìˆœ ëª¨ë“œ: í‰ë¬¸ í•„ë“œëª… (ì ‘ë‘ $ ë„£ì§€ ì•ŠìŒ)
							lk
								.append( "localField", spec.localField )
								.append( "foreignField", spec.foreignField );

						} else {
							List<Document> pipe = new ArrayList<>();

							// 1) ì˜¤ë¥¸ìª½ ì¼ë°˜ í•„í„°ë¥¼ ë¨¼ì € (ì¸ë±ìŠ¤ íƒ€ê²Œ)
							rightMatch.ifPresent( rc -> pipe.add( new Document( "$match", rc.getCriteriaObject() ) ) );

							// 2) local/foreign ìˆë‹¤ë©´ $expr ì¡°ì¸ì‹ ì¶”ê°€ (let í•„ìš”)
							if (spec.localField != null && spec.foreignField != null) {
								String lfVar = "vlf"; // ë°˜ë“œì‹œ ì˜ë¬¸ìë¡œ ì‹œì‘
								lk.append( "let", new Document( lfVar, "$" + spec.localField ) );
								pipe
									.add(
										new Document(
											"$match",
											new Document(
												"$expr",
												new Document( "$eq", Arrays.asList( "$" + spec.foreignField, "$$" + lfVar ) )
											)
										)
									);

							} else {
								// let ê·¸ëŒ€ë¡œ ìœ ì§€ (ì—†ìœ¼ë©´ ë¹ˆ Document)
								lk.append( "let", Optional.ofNullable( spec.letDoc ).orElseGet( Document::new ) );

							}

							boolean onlyProjects = ! nonLimitStages.isEmpty() && nonLimitStages.stream().allMatch( st -> st.containsKey( "$project" ) );

							if (onlyProjects) {
								// EXISTS ìµœì í™”: limit â†’ project (í›„ë³´ë¥¼ 1ê±´ìœ¼ë¡œ ì¤„ì¸ ë‹¤ìŒ project)
								pipe.addAll( limitStages );
								pipe.addAll( nonLimitStages );

							} else {
								// ì¼ë°˜ ì¼€ì´ìŠ¤: ê¸°ì¡´ ìˆœì„œ ìœ ì§€
								pipe.addAll( nonLimitStages );
								pipe.addAll( limitStages );

							}

							lk.append( "pipeline", pipe );

						}

						ops.add( ctx -> new Document( "$lookup", lk ) );

						if (spec.unwind) {
							ops
								.add(
									ctx -> new Document(
										"$unwind",
										new Document( "path", "$" + rightAs )
											.append( "preserveNullAndEmptyArrays", spec.preserveNullAndEmptyArrays )
									)
								);

						}

						if (spec.getOuterStages() != null) {
							for (Document st : spec.getOuterStages())
								ops.add( ctx -> st ); // â† lookup ì´í›„ í•„í„°

						}

						if (spec.unwind) {

							// ê·¸ë£¹ìœ¼ë¡œ ì™¼ìª½/ì˜¤ë¥¸ìª½ ì¹´ìš´íŠ¸ ë™ì‹œ ê³„ì‚°
							Document group = new Document(
								"$group",
								new Document( "_id", null )
									.append( "leftCount", new Document( "$sum", 1 ) )
									.append(
										"rightCount",
										new Document(
											"$sum",
											new Document(
												"$cond",
												List
													.of(
														new Document( "$ifNull", List.of( "$" + rightAs, null ) ),
														1,
														0
													)
											)
										)
									)
							);
							ops.add( ctx -> group );

						} else {
							// ë°°ì—´ í¬ê¸°ë¥¼ ë”í•´ì„œ ì˜¤ë¥¸ìª½ ì´ ë§¤ì¹­ ìˆ˜ë¥¼ ê³„ì‚°
							Document setSize = new Document(
								"$set",
								new Document(
									"_rightSize",
									new Document(
										"$size",
										new Document( "$ifNull", List.of( "$" + rightAs, List.of() ) )
									)
								)
							);
							ops.add( ctx -> setSize );

							Document group = new Document(
								"$group",
								new Document( "_id", null )
									.append( "leftCount", new Document( "$sum", 1 ) )
									.append( "rightCount", new Document( "$sum", "$_rightSize" ) )
							);
							ops.add( ctx -> group );

						}

						Aggregation agg = applyAggOptions( Aggregation.newAggregation( ops ) );

						// agg.withOptions( Aggregation.newAggregationOptions().allowDiskUse( false ).build() );
						return agg;

					} );

				return Mono
					.zip( leftClassMono, rightClassMono, aggMono )
					.flatMap( tp -> {
						Class<E> leftClass = tp.getT1();
						Class<R2> rightClass = tp.getT2();
						Aggregation agg = tp.getT3();

						Flux<Document> docs = (collectionName != null && ! collectionName.isBlank())
							? reactiveMongoTemplate.aggregate( agg, collectionName, Document.class )
							: reactiveMongoTemplate.aggregate( agg, leftClass, Document.class );

						String leftName = simpleName( leftClass );
						String rightName = simpleName( rightClass );

						return docs
							.singleOrEmpty()
							.map( d -> {
								long lc = Optional.ofNullable( d.get( "leftCount", Number.class ) ).map( Number::longValue ).orElse( 0L );
								long rc = Optional.ofNullable( d.get( "rightCount", Number.class ) ).map( Number::longValue ).orElse( 0L );
								return new ResultTuple<>( leftName, lc, rightName, rc );

							} )
							.defaultIfEmpty( new ResultTuple<>( leftName, 0L, rightName, 0L ) );

					} );

			}

			public Mono<Long> execute() {

				var queryMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					Query query = new Query();

					if (criteriaOptional.isPresent()) {
						query.addCriteria( criteriaOptional.get() );

					}

					applyQueryOptions( query );

					return query;

				} );
				return Mono
					.zip( executeClassMono, queryMono )
					.flatMap( tuple -> {

						var entityClass = tuple.getT1();
						var query = tuple.getT2();
						if (collectionName != null && ! collectionName.isBlank())
							return reactiveMongoTemplate.count( query, entityClass, collectionName );
						else
							return reactiveMongoTemplate.count( query, entityClass );

					} )
				// .onErrorMap( e -> new RuntimeException( "Failed to count documents: " + e.getMessage(), e ) )
				;

			}

			public Mono<Long> executeAggregation() {

				Mono<Aggregation> aggMono = fieldBuilder.buildCriteria().map( criteriaOpt -> {
					List<AggregationOperation> ops = new ArrayList<>();

					// where ì ˆ($match)
					criteriaOpt.ifPresent( c -> ops.add( Aggregation.match( c ) ) );

					// ì¹´ìš´íŠ¸
					ops.add( ctx -> new Document( "$count", "count" ) );

					Aggregation agg = applyAggOptions( Aggregation.newAggregation( ops ) );

					return agg;

				} );

				return Mono
					.zip( executeClassMono, aggMono )
					.flatMap( tuple -> {
						Class<E> entityClass = tuple.getT1();
						Aggregation aggregation = tuple.getT2();

						Flux<Document> docs = (collectionName != null && ! collectionName.isBlank())
							? reactiveMongoTemplate.aggregate( aggregation, collectionName, Document.class )
							: reactiveMongoTemplate.aggregate( aggregation, entityClass, Document.class );

						return docs
							.singleOrEmpty()
							.map( d -> {
								Number n = d.get( "count", Number.class );
								return (n == null) ? 0L : n.longValue();

							} )
							.defaultIfEmpty( 0L );

					} );

			}

		}

		public class DeleteQueryBuilder {

			public Mono<DeleteResult> execute() {

				var queryMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					Query query = new Query();

					if (criteriaOptional.isPresent()) {
						query.addCriteria( criteriaOptional.get() );

					}

					return query;

				} );
				return Mono
					.zip( executeClassMono, queryMono )
					.flatMap( tuple -> {
						var entityClass = tuple.getT1();
						var query = tuple.getT2();
						if (collectionName != null && ! collectionName.isBlank())
							return reactiveMongoTemplate.remove( query, entityClass, collectionName );
						else
							return reactiveMongoTemplate.remove( query, entityClass );

					} )
				// .onErrorMap( e -> new RuntimeException( "Failed to delete documents: " + e.getMessage(), e ) )
				;

			}

		}

		public class ExistsQueryBuilder extends QueryBuilderAccesser {

			public <R2  > Mono<ResultTuple<Boolean, Boolean>> executeLookup(
				AbstractQueryBuilder<R2, ?>.FindAllQueryBuilder<R2> rightBuilder, LookupSpec spec
			) {

				Mono<Class<E>> leftClassMono = executeClassMono;
				Mono<Class<R2>> rightClassMono = rightBuilder.getExecuteClassMono();

				Mono<Aggregation> aggMono = Mono
					.zip(
						fieldBuilder.buildCriteria(),
						rightBuilder.getFieldBuilderCriteria(),
						leftClassMono,
						rightClassMono
					)
					.map( tp -> {
						Optional<Criteria> leftMatch = tp.getT1();
						Optional<Criteria> rightMatch = tp.getT2();
						// Class<E> leftClass = tp.getT3();
						Class<R2> rightClass = tp.getT4();

						String rightColl = (rightBuilder.getCollectionName() != null && ! rightBuilder.getCollectionName().isBlank())
							? rightBuilder.getCollectionName()
							: rightBuilder.resolveCollectionName( rightClass );

						String rightAs = (spec.as != null && ! spec.as.isBlank()) ? spec.as : simpleName( rightClass );

						List<AggregationOperation> ops = new ArrayList<>();
						leftMatch.ifPresent( c -> ops.add( Aggregation.match( c ) ) );

						Document lk = new Document( "from", rightColl ).append( "as", rightAs );


						// spec.pipelineDocs ë¶„í•´: $limit(ë“¤)ì€ ëìœ¼ë¡œ ë³´ë‚´ê¸° ìœ„í•´ ë”°ë¡œ ëª¨ì•„ë‘ 
						List<Document> userStages = Optional.ofNullable( spec.pipelineDocs ).orElseGet( List::of );
						List<Document> nonLimitStages = new ArrayList<>();
						List<Document> limitStages = new ArrayList<>();

						for (Document st : userStages) {
							if (st.containsKey( "$limit" ))
								limitStages.add( st );
							else
								nonLimitStages.add( st );

						}

						boolean needPipeline = (spec.localField == null || spec.foreignField == null) // ì›ë˜ pipeline ëª¨ë“œ
							|| rightMatch.isPresent() // ì˜¤ë¥¸ìª½ ì¶”ê°€ í•„í„° ìˆìŒ
							|| ! nonLimitStages.isEmpty() || ! limitStages.isEmpty(); // ì‚¬ìš©ìê°€ ë„£ì€ stage ìˆìŒ

						if (! needPipeline) {
							// ë‹¨ìˆœ ëª¨ë“œ: í‰ë¬¸ í•„ë“œëª… (ì ‘ë‘ $ ë„£ì§€ ì•ŠìŒ)
							lk
								.append( "localField", spec.localField )
								.append( "foreignField", spec.foreignField );

						} else {
							List<Document> pipe = new ArrayList<>();

							// 1) ì˜¤ë¥¸ìª½ ì¼ë°˜ í•„í„°ë¥¼ ë¨¼ì € (ì¸ë±ìŠ¤ íƒ€ê²Œ)
							rightMatch.ifPresent( rc -> pipe.add( new Document( "$match", rc.getCriteriaObject() ) ) );

							// 2) local/foreign ìˆë‹¤ë©´ $expr ì¡°ì¸ì‹ ì¶”ê°€ (let í•„ìš”)
							if (spec.localField != null && spec.foreignField != null) {
								String lfVar = "vlf"; // ë°˜ë“œì‹œ ì˜ë¬¸ìë¡œ ì‹œì‘
								lk.append( "let", new Document( lfVar, "$" + spec.localField ) );
								pipe
									.add(
										new Document(
											"$match",
											new Document(
												"$expr",
												new Document( "$eq", Arrays.asList( "$" + spec.foreignField, "$$" + lfVar ) )
											)
										)
									);

							} else {
								// let ê·¸ëŒ€ë¡œ ìœ ì§€ (ì—†ìœ¼ë©´ ë¹ˆ Document)
								lk.append( "let", Optional.ofNullable( spec.letDoc ).orElseGet( Document::new ) );

							}

							boolean onlyProjects = ! nonLimitStages.isEmpty() && nonLimitStages.stream().allMatch( st -> st.containsKey( "$project" ) );

							if (onlyProjects) {
								// EXISTS ìµœì í™”: limit â†’ project (í›„ë³´ë¥¼ 1ê±´ìœ¼ë¡œ ì¤„ì¸ ë‹¤ìŒ project)
								pipe.addAll( limitStages );
								pipe.addAll( nonLimitStages );

							} else {
								// ì¼ë°˜ ì¼€ì´ìŠ¤: ê¸°ì¡´ ìˆœì„œ ìœ ì§€
								pipe.addAll( nonLimitStages );
								pipe.addAll( limitStages );

							}

							lk.append( "pipeline", pipe );

						}

						ops.add( ctx -> new Document( "$lookup", lk ) );

						if (spec.unwind) {
							ops
								.add(
									ctx -> new Document(
										"$unwind",
										new Document( "path", "$" + rightAs )
											.append( "preserveNullAndEmptyArrays", spec.preserveNullAndEmptyArrays )
									)
								);

						}

						if (spec.getOuterStages() != null) {
							for (Document st : spec.getOuterStages())
								ops.add( ctx -> st ); // â† lookup ì´í›„ í•„í„°

						}

						// ì˜¤ë¥¸ìª½ ì¡´ì¬ í”Œë˜ê·¸ ê³„ì‚°
						Document rightExistsExpr = spec.unwind
							? new Document( "$gt", List.of( new Document( "$type", "$" + rightAs ), "missing" ) )
							: new Document(
								"$gt",
								List
									.of(
										new Document(
											"$size",
											new Document( "$ifNull", List.of( "$" + rightAs, List.of() ) )
										),
										0
									)
							);

						ops
							.add(
								ctx -> new Document(
									"$project",
									new Document( "_rightExists", rightExistsExpr )
								)
							);

						ops.add( Aggregation.limit( 1 ) ); // ì™¼ìª½ ì¡´ì¬ì—¬ë¶€ íŒì •

						Aggregation agg = applyAggOptions( Aggregation.newAggregation( ops ) );

						agg.withOptions( Aggregation.newAggregationOptions().allowDiskUse( false ).build() );
						return agg;

					} );

				return Mono
					.zip( leftClassMono, rightClassMono, aggMono )
					.flatMap( tp -> {
						Class<E> leftClass = tp.getT1();
						Class<R2> rightClass = tp.getT2();
						Aggregation agg = tp.getT3();

						Flux<Document> docs = (collectionName != null && ! collectionName.isBlank())
							? reactiveMongoTemplate.aggregate( agg, collectionName, Document.class )
							: reactiveMongoTemplate.aggregate( agg, leftClass, Document.class );

						String leftName = simpleName( leftClass );
						String rightName = simpleName( rightClass );

						Mono<Document> firstDocMono = docs.next();

						return firstDocMono
							.map( d -> {
								boolean rightExists = Optional.ofNullable( d.get( "_rightExists", Boolean.class ) ).orElse( false );
								return new ResultTuple<>( leftName, true, rightName, rightExists );

							} )
							.defaultIfEmpty( new ResultTuple<>( leftName, false, rightName, false ) );

					} );

			}

			public Mono<Boolean> execute() {

				var queryMono = fieldBuilder.buildCriteria().map( criteriaOptional -> {
					Query query = new Query();

					if (criteriaOptional.isPresent()) {
						query.addCriteria( criteriaOptional.get() );

					}

					applyQueryOptions( query );

					return query;

				} );
				return Mono
					.zip( executeClassMono, queryMono )
					.flatMap( tuple -> {
						var entityClass = tuple.getT1();
						var query = tuple.getT2();
						if (collectionName != null && ! collectionName.isBlank())
							return reactiveMongoTemplate.exists( query, entityClass, collectionName );
						else
							return reactiveMongoTemplate.exists( query, entityClass );

					} )
				// .onErrorMap( e -> new RuntimeException( "Failed to check existence: " + e.getMessage(), e ) )
				;

			}

		}

		public class AtomicUpdateQueryBuilder {
		
		    private final Update update = new Update();
		
		    // ê¸°ë³¸ì€ ì•ˆì „í•˜ê²Œ updateFirst(= 1ê±´)ë¡œ
		    private boolean multi = false;
		    private boolean upsert = false;
		
		    /** ì—¬ëŸ¬ ê±´ ì—…ë°ì´íŠ¸ë¡œ ë³€ê²½ (updateMulti) */
		    public AtomicUpdateQueryBuilder multi() {
		        this.multi = true;
		        return this;
		    }
		
		    /** ë‹¨ê±´ ì—…ë°ì´íŠ¸ë¡œ ë³€ê²½ (updateFirst) */
		    public AtomicUpdateQueryBuilder first() {
		        this.multi = false;
		        return this;
		    }
		
		    /** upsertë¡œ ì‹¤í–‰ */
		    public AtomicUpdateQueryBuilder upsert() {
		        this.upsert = true;
		        return this;
		    }
		
		    // --------------------
		    // update operators
		    // --------------------
		
		    private String requireField(String field) {
		        if (field == null || field.isBlank()) {
		            throw new IllegalArgumentException("field must not be null/blank");
		        }
		        return field;
		    }
		
		    public AtomicUpdateQueryBuilder inc(String field, Number delta) {
		        update.inc(requireField(field), delta);
		        return this;
		    }
		
		    public AtomicUpdateQueryBuilder inc(Enum<?> field, Number delta) {
		        return inc(field.name(), delta);
		    }
		
		    public AtomicUpdateQueryBuilder set(String field, Object value) {
		        update.set(requireField(field), value);
		        return this;
		    }
		
		    public AtomicUpdateQueryBuilder set(Enum<?> field, Object value) {
		        return set(field.name(), value);
		    }
		
		    public AtomicUpdateQueryBuilder unset(String field) {
		        update.unset(requireField(field));
		        return this;
		    }
		
		    public AtomicUpdateQueryBuilder unset(Enum<?> field) {
		        return unset(field.name());
		    }
		
		    public AtomicUpdateQueryBuilder push(String field, Object value) {
		        update.push(requireField(field), value);
		        return this;
		    }
		
		    public AtomicUpdateQueryBuilder addToSet(String field, Object value) {
		        update.addToSet(requireField(field), value);
		        return this;
		    }
		
		    public AtomicUpdateQueryBuilder pull(String field, Object value) {
		        update.pull(requireField(field), value);
		        return this;
		    }
		
		    /** ì‹¤ì œ ì‹¤í–‰ */
		    public Mono<UpdateResult> execute() {
		
		        // update ì—°ì‚°ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì‹¤ìˆ˜ ë°©ì§€
		        if (update.getUpdateObject() == null || update.getUpdateObject().isEmpty()) {
		            return Mono.error(new IllegalStateException("No update operation specified (e.g. inc/set/unset)."));
		        }
		
		        var queryMono = fieldBuilder.buildCriteria().map(criteriaOptional -> {
		            Query query = new Query();
		            criteriaOptional.ifPresent(query::addCriteria);
		            return query;
		        });
		
		        return Mono.zip(executeClassMono, queryMono)
		            .flatMap(tuple -> {
		                Class<E> entityClass = tuple.getT1();
		                Query query = tuple.getT2();
		
		                // collectionName ì§€ì • ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°
		                if (collectionName != null && !collectionName.isBlank()) {
		                    if (upsert) return reactiveMongoTemplate.upsert(query, update, entityClass, collectionName);
		                    if (multi)  return reactiveMongoTemplate.updateMulti(query, update, entityClass, collectionName);
		                    return reactiveMongoTemplate.updateFirst(query, update, entityClass, collectionName);
		                }
		
		                if (upsert) return reactiveMongoTemplate.upsert(query, update, entityClass);
		                if (multi)  return reactiveMongoTemplate.updateMulti(query, update, entityClass);
		                return reactiveMongoTemplate.updateFirst(query, update, entityClass);
		            });
		    }
		
		    /** ìì£¼ ì“°ë©´ í¸ì˜ ë©”ì„œë“œ */
		    public Mono<Long> executeModifiedCount() {
		        return execute().map(UpdateResult::getModifiedCount);
		    }
		}

	}


	public class ExecuteRepositoryBuilder<E> extends AbstractQueryBuilder<E, ExecuteRepositoryBuilder<E>> implements ExecuteBuilder {

		// private final Class<? extends ReactiveCrudRepository<?, ?>> repositoryClass;

		ExecuteRepositoryBuilder(
									K key,
									Class<? extends ReactiveCrudRepository<?, ?>> repositoryClass
		) {

			this.repositoryClass = repositoryClass;
			this.reactiveMongoTemplate = MongoQueryBuilder.this.getMongoTemplate( key );
			this.executeClassMono = extractEntityClass( repositoryClass );
			this.executeBuilder = this;

		}

	}

	public class ExecuteEntityBuilder<E> extends AbstractQueryBuilder<E, ExecuteEntityBuilder<E>> implements ExecuteBuilder {

		@SuppressWarnings("unchecked")
		ExecuteEntityBuilder(
								K key
		) {

			this.executeClassMono = Mono
				.just(
					(Class<E>) ((ParameterizedType) getClass()
						.getGenericSuperclass()).getActualTypeArguments()[0]
				);

			// ğŸ”¥ í•µì‹¬: applicationContext ëŒ€ì‹  resolverë¥¼ í†µí•´ í…œí”Œë¦¿ íšë“
			this.reactiveMongoTemplate = MongoQueryBuilder.this.getMongoTemplate( key );
			this.executeBuilder = this;

		}

		ExecuteEntityBuilder(
								Class<E> executeClass,
								K key
		) {

			this.executeClassMono = Mono.just( executeClass );
			this.reactiveMongoTemplate = MongoQueryBuilder.this.getMongoTemplate( key );
			this.executeBuilder = this;

		}

	}

	public class ExecuteCustomClassBuilder<E> extends AbstractQueryBuilder<E, ExecuteCustomClassBuilder<E>> implements ExecuteBuilder {

		@SuppressWarnings("unchecked")
		ExecuteCustomClassBuilder(
									K key,
									String collectionName
		) {

			this.executeClassMono = Mono
				.just(
					(Class<E>) ((ParameterizedType) getClass()
						.getGenericSuperclass()).getActualTypeArguments()[0]
				);

			this.reactiveMongoTemplate = MongoQueryBuilder.this.getMongoTemplate( key );
			this.collectionName = collectionName;
			this.executeBuilder = this;

		}

		ExecuteCustomClassBuilder(
									Class<E> executeClass,
									K key,
									String collectionName
		) {

			this.executeClassMono = Mono.just( executeClass );
			this.reactiveMongoTemplate = MongoQueryBuilder.this.getMongoTemplate( key );
			this.collectionName = collectionName;
			this.executeBuilder = this;

		}

	}

	public <E> ExecuteRepositoryBuilder<E> executeRepository(
		K key, Class<? extends ReactiveCrudRepository<?, ?>> repositoryClass
	) {

		return new ExecuteRepositoryBuilder<>( key, repositoryClass );
	}

	public <E> ExecuteEntityBuilder<E> executeEntity(
		K key
	) {

		return new ExecuteEntityBuilder<>( key );
	}

	public <E> ExecuteEntityBuilder<E> executeEntity(
		Class<E> executeEntity, K key
	) {

		return new ExecuteEntityBuilder<>( executeEntity, key );
	}

	public <E> ExecuteCustomClassBuilder<E> executeCustomClass(
		Class<E> executeCustomClass, K key, String collectionName
	) {

		return new ExecuteCustomClassBuilder<>( executeCustomClass, key, collectionName );
	}

	public <E> ExecuteCustomClassBuilder<E> executeCustomClass(
		K key, String collectionName
	) {

		return new ExecuteCustomClassBuilder<>( key, collectionName );
	}


	public static class PageResult<E> {

		private final List<E> data;

		private final Long totalCount;

		public List<E> getData() { return this.data; }

		public Long getTotalCount() { return this.totalCount; }

		public PageResult() {

			this.data = Collections.emptyList();
			this.totalCount = 0L;

		}

		public PageResult(
							Long totalCount
		) {

			this.data = Collections.emptyList();
			this.totalCount = totalCount;

		}

		public PageResult(
							List<E> data
		) {

			this.data = data;
			this.totalCount = 0L;

		}

		public PageResult(
							List<E> data,
							Long totalCount
		) {

			this.data = data;
			this.totalCount = totalCount;

		}

		public boolean isEmpty() { return data == null || data.isEmpty(); }

		public int size() {

			return data == null ? 0 : data.size();

		}

		public static <E> PageResult<E> empty() {

			return new PageResult<>( Collections.emptyList(), 0L );

		}

		public static <E> PageResult<E> of(
			List<E> data, long totalCount
		) {

			return new PageResult<>( data, totalCount );

		}

		public <R> PageResult<R> map(
			Function<? super E, ? extends R> mapper
		) {

			Objects.requireNonNull( mapper, "mapper" );
			List<R> mapped = (data == null ? Collections.<E>emptyList() : data)
				.stream()
				.map( mapper )
				.collect( Collectors.toList() );
			return new PageResult<>( mapped, totalCount );

		}

		/** ì´ í˜ì´ì§€ ìˆ˜ (pageSize > 0 í•„ìš”). totalCountê°€ nullì´ë©´ 0ìœ¼ë¡œ ê°€ì • */
		public int totalPages(
			int pageSize
		) {

			if (pageSize <= 0)
				throw new IllegalArgumentException( "pageSize must be > 0" );
			long tc = (totalCount == null) ? 0L : totalCount;
			if (tc == 0L)
				return 0;
			return (int) ((tc + pageSize - 1) / pageSize); // ceil

		}

		/** ë‹¤ìŒ í˜ì´ì§€ ì¡´ì¬ ì—¬ë¶€. pageëŠ” 0-based. totalCountê°€ nullì´ë©´ falseë¡œ ê°€ì • */
		public boolean hasNext(
			int page, int pageSize
		) {

			if (page < 0 || pageSize <= 0)
				throw new IllegalArgumentException( "invalid page/pageSize" );
			long tc = (totalCount == null) ? 0L : totalCount;
			long shown = (long) (page + 1) * pageSize;
			return shown < tc;

		}

		public <R> PageResult<R> mapNotNull(
			Function<? super E, ? extends R> mapper
		) {

			Objects.requireNonNull( mapper, "mapper" );
			List<R> mapped = (data == null ? Collections.<E>emptyList() : data)
				.stream()
				.map( mapper )
				.filter( Objects::nonNull )
				.collect( Collectors.toList() );
			return new PageResult<>( mapped, totalCount );

		}

		/** ì™¸ë¶€ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•˜ì§€ ëª»í•˜ê²Œ í•˜ëŠ” ì½ê¸° ì „ìš© ë·° */
		public List<E> asUnmodifiableData() {

			return Collections.unmodifiableList( data == null ? Collections.emptyList() : data );

		}

		/** ì¡°ê±´ìœ¼ë¡œ dataë¥¼ í•„í„°ë§ (totalCountëŠ” ì›ë³¸ ê°’ ìœ ì§€) */
		public PageResult<E> filter(
			Predicate<? super E> predicate
		) {

			Objects.requireNonNull( predicate, "predicate" );
			List<E> filtered = (data == null ? Collections.<E>emptyList() : data)
				.stream()
				.filter( predicate )
				.collect( Collectors.toList() );
			return new PageResult<>( filtered, totalCount );

		}

		/** ì¡°ê±´ìœ¼ë¡œ dataë¥¼ í•„í„°ë§í•˜ê³  totalCountë¥¼ ì¬ê³„ì‚° */
		public PageResult<E> filterAndRecount(
			Predicate<? super E> predicate
		) {

			Objects.requireNonNull( predicate, "predicate" );
			List<E> filtered = (data == null ? Collections.<E>emptyList() : data)
				.stream()
				.filter( predicate )
				.collect( Collectors.toList() );
			return new PageResult<>( filtered, (long) filtered.size() );

		}

		/** null ìš”ì†Œ ì œê±° (totalCountëŠ” ì›ë³¸ ìœ ì§€). í•„ìš” ì—†ìœ¼ë©´ ìƒëµ ê°€ëŠ¥ */
		public PageResult<E> filterNotNull() {

			List<E> filtered = (data == null ? Collections.<E>emptyList() : data)
				.stream()
				.filter( Objects::nonNull )
				.collect( Collectors.toList() );
			return new PageResult<>( filtered, totalCount );

		}

		/** ê° ìš”ì†Œì— ëŒ€í•´ ì‘ì—… ìˆ˜í–‰ (ì²´ì´ë‹ì´ í•„ìš” ì—†ì„ ë•Œ) */
		public void forEach(
			Consumer<? super E> action
		) {

			Objects.requireNonNull( action, "action" );
			if (data != null)
				data.forEach( action );

		}

		/** ê° ìš”ì†Œì— ëŒ€í•´ ì‘ì—… ìˆ˜í–‰ í›„ this ë°˜í™˜ (ì²´ì´ë‹ìš©) */
		public PageResult<E> onEach(
			Consumer<? super E> action
		) {

			Objects.requireNonNull( action, "action" );
			if (data != null)
				data.forEach( action );
			return this;

		}

		/** ì¸ë±ìŠ¤ê°€ í•„ìš”í•œ ìˆœíšŒ */
		public void forEachIndexed(
			BiConsumer<Integer, ? super E> action
		) {

			Objects.requireNonNull( action, "action" );
			if (data == null)
				return;

			for (int i = 0; i < data.size(); i++) {
				action.accept( i, data.get( i ) );

			}

		}

	}


	public static class ResultTuple<L, R> {

		private String leftName; // í˜„ì¬ ì¿¼ë¦¬ ë¹Œë”ì˜ executeClass ì´ë¦„

		private L left; // í˜„ì¬ ì¿¼ë¦¬ ë¹Œë”ì˜ ê²°ê³¼ (ì—”í‹°í‹° 1ê°œ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)

		private String rightName; // ë§¤ê°œë³€ìˆ˜ ë¹Œë”ì˜ executeClass ì´ë¦„

		private R right; // ë§¤ê°œë³€ìˆ˜ ë¹Œë”ì˜ ê²°ê³¼ (ì—”í‹°í‹° 1ê°œ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)

		private Long totalCount;

		public ResultTuple(
							String leftName,
							L left,
							String rightName,
							R right
		) {

			this.leftName = leftName;
			this.left = left;
			this.rightName = rightName;
			this.right = right;

		}

		public ResultTuple(
							String leftName,
							L left,
							String rightName,
							R right,
							Long totalCount
		) {

			this.leftName = leftName;
			this.left = left;
			this.rightName = rightName;
			this.right = right;
			this.totalCount = totalCount;

		}

		public String getLeftName() { return leftName; }

		public void setLeftName(
			String leftName
		) { this.leftName = leftName; }

		public L getLeft() { return left; }

		public void setLeft(
			L left
		) { this.left = left; }

		public String getRightName() { return rightName; }

		public void setRightName(
			String rightName
		) { this.rightName = rightName; }

		public R getRight() { return right; }

		public void setRight(
			R right
		) { this.right = right; }

		public Long getTotalCount() { return totalCount; }

		public void setTotalCount(
			Long totalCount
		) { this.totalCount = totalCount; }


		@SuppressWarnings("unchecked")
		public <T> T getRightIfListFirst() {

			if (right == null)
				return null;

			if (right instanceof List<?> list) { return list.isEmpty() ? null : (T) list.get( 0 ); }

			return (T) right;

		}

	}

	public final class PageStream<T> {

		private final Flux<T> data;

		private final Mono<Long> totalCount;

		public PageStream(
							Flux<T> data,
							Mono<Long> totalCount
		) {

			this.data = (data == null) ? Flux.empty() : data;
			this.totalCount = (totalCount == null) ? Mono.just( 0L ) : totalCount;

		}

		/** totalCountë¥¼ ë°”ë¡œ ì•Œê³  ìˆì„ ë•Œ í¸ì˜ ìƒì„±ì */
		public PageStream(
							Flux<T> data,
							long totalCount
		) {

			this( data, Mono.just( totalCount ) );

		}

		public Flux<T> data() {

			return data;

		}

		public Mono<Long> totalCount() {

			return totalCount;

		}

		// ----------------------------------------------------------------------
		// í—¬í¼ë“¤ (PageResult ì™€ ë¹„ìŠ·í•œ ì—­í• , reactive ìŠ¤íƒ€ì¼ë¡œ)
		// ----------------------------------------------------------------------

		/** totalCount ê¸°ì¤€ìœ¼ë¡œ ë¹„ì–´ìˆëŠ”ì§€ ì—¬ë¶€ */
		public Mono<Boolean> isEmpty() { return totalCount
			.defaultIfEmpty( 0L )
			.map( tc -> tc == 0L ); }

		/**
		 * í˜„ì¬ í˜ì´ì§€(data Flux)ê°€ ëª‡ ê°œë¥¼ ë‚´ë³´ë‚´ëŠ”ì§€ ì¹´ìš´íŠ¸.
		 * (PageResultì˜ size()ì— ëŒ€ì‘, ì „ì²´ totalCountê°€ ì•„ë‹ˆë¼ "í˜„ì¬ í˜ì´ì§€ í¬ê¸°")
		 */
		public Mono<Long> size() {

			return data.count();

		}

		/** ê° ìš”ì†Œë¥¼ ë‹¤ë¥¸ íƒ€ì…ìœ¼ë¡œ ë§¤í•‘ (totalCountëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€) */
		public <R> PageStream<R> map(
			Function<? super T, ? extends R> mapper
		) {

			Objects.requireNonNull( mapper, "mapper" );
			return MongoQueryBuilder.this.new PageStream<>( data.map( mapper ), totalCount );

		}

		/** null ê²°ê³¼ëŠ” ì œê±°í•˜ë©´ì„œ ë§¤í•‘ */
		public <R> PageStream<R> mapNotNull(
			Function<? super T, ? extends R> mapper
		) {

			Objects.requireNonNull( mapper, "mapper" );

			return MongoQueryBuilder.this.new PageStream<>(
				data
					.<R>map( mapper )
					.filter( Objects::nonNull ),
				totalCount
			);
		}

		/** data ìŠ¤íŠ¸ë¦¼ì„ í•„í„°ë§ (totalCountëŠ” ì›ë³¸ ê°’ì„ ê·¸ëŒ€ë¡œ ìœ ì§€) */
		public PageStream<T> filter(
			Predicate<? super T> predicate
		) {

			Objects.requireNonNull( predicate, "predicate" );
			return MongoQueryBuilder.this.new PageStream<>(
				data.filter( predicate::test ),
				totalCount
			);

		}

		/** null ìš”ì†Œ ì œê±° (totalCountëŠ” ì›ë³¸ ìœ ì§€) */
		public PageStream<T> filterNotNull() {

			return MongoQueryBuilder.this.new PageStream<>(
				data.filter( Objects::nonNull ),
				totalCount
			);

		}

		/** ê° ìš”ì†Œì— ëŒ€í•´ ë¶€ìˆ˜íš¨ê³¼ë¥¼ ìˆ˜í–‰í•˜ê³ , ë‹¤ì‹œ PageStream ìœ¼ë¡œ ëŒë ¤ì¤Œ (ì²´ì´ë‹ìš©) */
		public PageStream<T> onEach(
			Consumer<? super T> action
		) {

			Objects.requireNonNull( action, "action" );
			return MongoQueryBuilder.this.new PageStream<>(
				data.doOnNext( action ),
				totalCount
			);

		}

		/** ë‹¨ìˆœ ì†Œë¹„ìš©(forEachì™€ ë¹„ìŠ·) â€“ subscribeëŠ” í˜¸ì¶œí•˜ëŠ” ìª½ì—ì„œ */
		public Mono<Void> forEach(
			Consumer<? super T> action
		) {

			Objects.requireNonNull( action, "action" );
			return data
				.doOnNext( action )
				.then();

		}

		/** ì¸ë±ìŠ¤ë¥¼ í•¨ê»˜ ì“°ëŠ” ìˆœíšŒ (PageResult.forEachIndexed ëŒ€ì‘) */
		public Mono<Void> forEachIndexed(
			BiConsumer<Integer, ? super T> action
		) {

			Objects.requireNonNull( action, "action" );
			return data
				.index()
				.doOnNext( t -> action.accept( t.getT1().intValue(), t.getT2() ) )
				.then();

		}

		/** totalCount ê¸°ì¤€ ì´ í˜ì´ì§€ ìˆ˜ ê³„ì‚° (pageSize > 0) */
		public Mono<Integer> totalPages(
			int pageSize
		) {

			if (pageSize <= 0) { return Mono.error( new IllegalArgumentException( "pageSize must be > 0" ) ); }

			return totalCount
				.defaultIfEmpty( 0L )
				.map( tc -> {
					if (tc == 0L)
						return 0;
					return (int) ((tc + pageSize - 1) / pageSize); // ceil

				} );

		}

		/** ë‹¤ìŒ í˜ì´ì§€ ì¡´ì¬ ì—¬ë¶€. pageëŠ” 0-based */
		public Mono<Boolean> hasNext(
			int page, int pageSize
		) {

			if (page < 0 || pageSize <= 0) { return Mono.error( new IllegalArgumentException( "invalid page/pageSize" ) ); }

			return totalCount
				.defaultIfEmpty( 0L )
				.map( tc -> {
					long shown = (long) (page + 1) * pageSize;
					return shown < tc;

				} );

		}

		/**
		 * ì´ PageStream ì„ í•œ ë²ˆì— Listë¡œ ëª¨ì•„ì„œ PageResultë¡œ ë³€í™˜.
		 * (ì „í†µì ì¸ PageResult APIì™€ í•¨ê»˜ ì“°ê³  ì‹¶ì„ ë•Œ)
		 */
		public Mono<PageResult<T>> collectToPageResult() {

			return Mono
				.zip(
					data.collectList(),
					totalCount.defaultIfEmpty( 0L )
				)
				.map( t -> new PageResult<>( t.getT1(), t.getT2() ) );

		}
	}
}
